{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU V2 param net\n",
    "\n",
    "class GRU_WFC_2(nn.Module):\n",
    "    def __init__(self,tile_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tile = tile_num\n",
    "        self.inp_channels = tile_num\n",
    "        self.op_channels = tile_num\n",
    "        self.k_size = 3\n",
    "        self.pad_size = 2\n",
    "        self.p_size = self.k_size//2\n",
    "        self.bias_scale = 0.25\n",
    "        self.para = False\n",
    "\n",
    "        # Separable convolutions taken straight from RAFT. Just rewrite at some point, or change for another faster convolution idk\n",
    "        self.convz1 = nn.Conv2d(self.num_tile, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.convr1 = nn.Conv2d(self.num_tile, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.convq1 = nn.Conv2d(self.num_tile*2, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "\n",
    "        self.convz2 = nn.Conv2d(self.num_tile, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.convr2 = nn.Conv2d(self.num_tile, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.convq2 = nn.Conv2d(self.num_tile*2, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "\n",
    "        self.p_1 = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_1 = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b1l = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w1l = nn.Linear(tile_num * 2, tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.p_2 = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_2 = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b2l = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w2l = nn.Linear(tile_num * 2, tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.p_3 = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_3 = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b3l = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w3l = nn.Linear(tile_num * 2, 2 * tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.p_1v = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_1v = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b1lv = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w1lv = nn.Linear(tile_num * 2, tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.p_2v = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_2v = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b2lv = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w2lv = nn.Linear(tile_num * 2, tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.p_3v = nn.Linear(tile_num**2, tile_num * 2)\n",
    "        self.lin_3v = nn.Linear(tile_num*2, tile_num*2)\n",
    "        self.b3lv = nn.Linear(tile_num * 2, tile_num) # bias parameters\n",
    "        self.w3lv = nn.Linear(tile_num * 2, 2 * tile_num * tile_num * self.k_size)\n",
    "\n",
    "        self.conv_cont_1 = nn.Conv2d(tile_num, tile_num, 3)\n",
    "        self.conv_cont_2 = nn.Conv2d(tile_num, tile_num, 3, 2, 1) # WxHxC -> W/2xH/2xtile_num\n",
    "        self.conv_var = nn.Conv2d(tile_num, tile_num, 3, 2, 1)\n",
    "        self.conv_mean = nn.Conv2d(tile_num, tile_num, 3, 2, 1) # W/2xH/2xtile_num - W/4xH/4xtile_num/2\n",
    "\n",
    "\n",
    "        expansion_ratio = 3\n",
    "\n",
    "\n",
    "        self.inter_cv1 = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv2 = nn.Conv2d(self.num_tile, self.num_tile//2, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv3 = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv4 = nn.Conv2d(self.num_tile//2, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "\n",
    "        self.inter_ch1 = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch2 = nn.Conv2d(self.num_tile, self.num_tile//2, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch3 = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch4 = nn.Conv2d(self.num_tile//2, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "\n",
    "        self.inter_skip = nn.Conv2d(self.num_tile*2, self.num_tile, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate_e = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate_r = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate = nn.Conv2d(self.num_tile, self.num_tile, self.k_size, 1, self.p_size)\n",
    "\n",
    "        self.sigma = torch.nn.Sigmoid()\n",
    "        self.phi = torch.nn.Tanh()\n",
    "        self.lRel = torch.nn.LeakyReLU(0.2)\n",
    "        self.pad = torch.nn.ZeroPad2d(1)\n",
    "\n",
    "       \n",
    "    def forward(self, h, key, iter, training, context_vector):\n",
    "\n",
    "        if self.para:\n",
    "            w1_h, b1_h, w2_h, b2_h, w3_h, b3_h, w1_v, b1_v, w2_v, b2_v, w3_v, b3_v = self.ParaNet(key)\n",
    "\n",
    "        for i in range(iter):\n",
    "\n",
    "            h  = self.deep_collapse(h)\n",
    "\n",
    "            if training:\n",
    "                if iter == 0:  \n",
    "                    h_ret = h.clone().unsqueeze(1)\n",
    "                else:  \n",
    "                    h_ret = torch.concat((h_ret, h.clone().unsqueeze(1)), dim = 1)\n",
    "\n",
    "        if training:  \n",
    "            return h_ret\n",
    "        else:  \n",
    "            return h\n",
    "\n",
    "    def deep_collapse(self, h):\n",
    "    \n",
    "        xskipv = h.clone()\n",
    "        xskiph = h.clone()\n",
    "        \n",
    "        v1 = self.inter_cv1(xskipv)\n",
    "        v2 = self.phi(self.inter_cv3(v1))\n",
    "        v3 = self.lRel(self.inter_cv2(xskipv))\n",
    "        v4 = self.sigma(self.inter_cv4(v3))\n",
    "        xskipv = xskipv * (1 - v4) + v2 * self.bias_scale\n",
    "\n",
    "        h1 = self.inter_ch1(xskiph)\n",
    "        h2 = self.phi(self.inter_ch3(h1))\n",
    "        h3 = self.lRel(self.inter_ch2(xskiph))\n",
    "        h4 = self.sigma(self.inter_ch4(h3))\n",
    "        xskiph = xskiph * (1 - h4) + h2 * self.bias_scale\n",
    "\n",
    "        xskip = torch.concat((xskipv, xskiph), dim=1)\n",
    "        xskip = self.sigma(self.inter_skip(xskip))\n",
    "        gate = self.sigma(self.inter_skip_gate(h))\n",
    "        h = h * (1 - gate) + self.phi(xskip) * gate \n",
    "\n",
    "        return h\n",
    "    \n",
    "    def paranet_collapse(self, h,  w1_h, b1_h, w2_h, b2_h, w3_h, b3_h, w1_v, b1_v, w2_v, b2_v, w3_v, b3_v):\n",
    "\n",
    "        # horizontal\n",
    "        hx = h\n",
    "        z = torch.sigmoid(F.conv2d(hx, w1_h, b1_h,padding = (0,self.pad_size)))\n",
    "        r = torch.sigmoid(F.conv2d(hx, w2_h, b2_h, padding = (0,self.pad_size)))\n",
    "        q = torch.tanh(F.conv2d(r*h, w3_h, b3_h, padding = (0,self.pad_size)))\n",
    "        h = (1-z) * h + z * q\n",
    "\n",
    "        # vertical\n",
    "        hx = h \n",
    "        z = torch.sigmoid(F.conv2d(hx, w1_v, b1_v,padding = (self.pad_size, 0)))\n",
    "        r = torch.sigmoid(F.conv2d(hx, w2_v, b2_v,padding = (self.pad_size,0)))\n",
    "        q = torch.tanh(F.conv2d(r*h, w3_v, b3_v, padding = (self.pad_size,0)))      \n",
    "        h = (1-z) * h + z * q\n",
    "\n",
    "        return h\n",
    "\n",
    "    def standard_collapse(self, h): # h is memory block. becomes map after pseudo wfc, key matrix\n",
    "            \n",
    "            #self.key_query(h, k)\n",
    "            #print('-----',h.shape, self.valid.shape)\n",
    "            x = h #torch.concat((h,self.valid.unsqueeze(0)),dim=1) # Append a binary vector to each wave space representing valididty w.r.t. each neighbor\n",
    "\n",
    "            # horizontal\n",
    "            hx = x\n",
    "            z = torch.sigmoid(self.convz1(hx))\n",
    "            r = torch.sigmoid(self.convr1(hx))\n",
    "            q = torch.tanh(self.convq1(torch.concat((r*h, x),dim=1)))        \n",
    "            h = (1-z) * h + z * q\n",
    "\n",
    "            # vertical\n",
    "            hx = x\n",
    "            z = torch.sigmoid(self.convz2(hx))\n",
    "            r = torch.sigmoid(self.convr2(hx))\n",
    "            q = torch.tanh(self.convq2(torch.concat((r*h, x),dim=1)))       \n",
    "            h = (1-z) * h + z * q\n",
    "\n",
    "            return h\n",
    "    \n",
    "    def ParaNet(self, key):\n",
    "       \n",
    "        # First horizontal convolution\n",
    "        w1 = self.p_1(key.flatten())\n",
    "        w1 = self.lin_1(w1)\n",
    "        b1_h = self.phi(self.b1l(w1)).squeeze() # bias params\n",
    "        w1_h = self.phi(self.w1l(w1)).reshape(self.op_channels, self.inp_channels, 1, self.k_size) # weight params\n",
    "        # second horizontal\n",
    "        w2 = self.p_2(key.flatten())\n",
    "        w2 = self.lin_2(w2)\n",
    "        b2_h = self.phi(self.b2l(w2)).squeeze() # bias params\n",
    "        w2_h = self.phi(self.w2l(w2)).reshape(self.op_channels, self.inp_channels, 1, self.k_size) # weight params\n",
    "        # third horizontal with concat\n",
    "        w3 = self.p_3(key.flatten())\n",
    "        w3 = self.lin_3(w3)\n",
    "        b3_h = self.phi(self.b3l(w3)).squeeze() # bias params\n",
    "        w3_h = self.phi(self.w3l(w3)).reshape(self.op_channels, 2 * self.inp_channels, 1, self.k_size) # weight params\n",
    "               \n",
    "\n",
    "        # First vertical convolution\n",
    "        w1 = self.p_1v(key.flatten())\n",
    "        w1 = self.lin_1v(w1)\n",
    "        b1_v = self.phi(self.b1lv(w1)).squeeze() # bias params\n",
    "        w1_v = self.phi(self.w1lv(w1)).reshape(self.op_channels, self.inp_channels, self.k_size, 1) # weight params\n",
    "       \n",
    "        w2 = self.p_2v(key.flatten())\n",
    "        w2 = self.lin_2v(w2)\n",
    "        b2_v = self.phi(self.b2lv(w2)).squeeze() # bias params\n",
    "        w2_v = self.phi(self.w2lv(w2)).reshape(self.op_channels, self.inp_channels, self.k_size, 1) # weight params\n",
    "\n",
    "        w3 = self.p_3v(key.flatten())\n",
    "        w3 = self.lin_3v(w3)\n",
    "        b3_v = self.phi(self.b3lv(w3)).squeeze() # bias params\n",
    "        w3_v = self.phi(self.w3lv(w3)).reshape(self.op_channels, 2 * self.inp_channels, self.k_size, 1) # weight params\n",
    "               \n",
    "\n",
    "        return w1_h, b1_h, w2_h, b2_h, w3_h, b3_h, w1_v, b1_v, w2_v, b2_v, w3_v, b3_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL WFC\n",
    "\n",
    "def actual_wfc(tile_space, width, height, key, seed, z):\n",
    "\n",
    "    wave_map = torch.ones((tile_space, width, height))\n",
    "    collapse_index = torch.zeros(width * height)\n",
    "\n",
    "    #if seed != None:\n",
    "    wave_map = wave_map * seed\n",
    "    collapse_index[z] = 1\n",
    "\n",
    "    wave_map = diffuse(wave_map, z//width, z%width, key, width, height)\n",
    "\n",
    "    key = key\n",
    "    collapsed = False\n",
    "    count = 0\n",
    "    if 1:\n",
    "        while not collapsed:\n",
    "            id_lin = choose(wave_map, collapse_index)\n",
    "            if id_lin >= 0:\n",
    "                cx = id_lin % width\n",
    "                cy = id_lin // width\n",
    "\n",
    "                wave_vec = wave_map[:,cy, cx].squeeze() #key_return(wave_map, cy, cx, height, width, key, 4)\n",
    "                tile = collapse(wave_vec)\n",
    "\n",
    "                wave_map[:, cy, cx] = tile\n",
    "                wave_map = diffuse(wave_map, cy, cx, key, width, height)\n",
    "                \n",
    "                collapse_index[cx + cy * width] = 1\n",
    "\n",
    "                if collapse_index.sum() == width * height or count > width*height + 10:\n",
    "                    collapsed = True\n",
    "                    if count > width*height + 10:\n",
    "                        print('out of time')\n",
    "                    break\n",
    "\n",
    "                count += 1\n",
    "\n",
    "    return wave_map\n",
    "\n",
    "def diffuse(map_, cy, cx, k, w, h):\n",
    "    cy = int(cy)\n",
    "    cx = int(cx)\n",
    "    vec = map_[:, cy, cx].unsqueeze(-1)\n",
    "\n",
    "    if cy-1 >= 0:\n",
    "        map_[:, cy-1,cx] = map_[:, cy-1,cx] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cy+1 < h:\n",
    "        map_[:, cy+1,cx] = map_[:, cy+1,cx] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cx-1 >= 0:\n",
    "        map_[:, cy, cx-1] = map_[:, cy, cx-1] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cx+1 < w:\n",
    "        map_[:, cy, cx+1] = map_[:, cy, cx+1] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "\n",
    "    return map_\n",
    "\n",
    "def collapse(x): \n",
    "    # X is current wavespace legality key\n",
    "    \n",
    "    probability = torch.softmax(torch.rand_like(x), dim=0) #*torch.softmax(freq, dim=0)\n",
    "    likelihood = x * probability #torch.matmul(key.T, probability.T)\n",
    "    _, tile_choice = torch.max(likelihood, dim=0)\n",
    "    x_collapse = torch.zeros_like(x)\n",
    "    x_collapse[tile_choice] = 1\n",
    "\n",
    "    return x_collapse\n",
    "    \n",
    "def key_return(map, cy, cx, h, w, key, num_adj):\n",
    "    \"\"\"\n",
    "    Unused cause it was wrong\n",
    "    \n",
    "    \"\"\"\n",
    "    vspace = torch.zeros(4, map.shape[0])\n",
    "    epsilon = 1e-3\n",
    "    if cy-1 >= 0:\n",
    "        vspace[0] = map[:,cy-1,cx]\n",
    "    else:\n",
    "        vspace[0,:] = 1\n",
    "    if cy+1 < h:\n",
    "        vspace[1] = map[:,cy+1,cx]\n",
    "    else:\n",
    "        vspace[1,:] = 1\n",
    "    if cx-1 >= 0:\n",
    "        vspace[2] = map[:,cy, cx-1]\n",
    "    else:\n",
    "        vspace[2,:] = 1\n",
    "    if cx+1 < w:\n",
    "        vspace[3] = map[:,cy, cx+1]\n",
    "    else:\n",
    "        vspace[3,:] = 1\n",
    "\n",
    "    vspace = torch.clamp(torch.matmul(key.unsqueeze(0), vspace.unsqueeze(-1)).squeeze(), 0, 1)\n",
    "    vspace = (torch.sum(vspace, dim=0) + epsilon) // num_adj\n",
    "\n",
    "    return vspace\n",
    "\n",
    "def choose(map_, collapse_list):\n",
    "    x_sum = torch.sum(map_,dim=0)\n",
    "    x_sumf = x_sum.flatten()\n",
    "    v, id = x_sumf.sort()\n",
    "    idx = -1\n",
    "\n",
    "    for k in range((v.shape[0])):\n",
    "        if collapse_list[id[k]] == 0:\n",
    "            idx = id[k]\n",
    "            break\n",
    "\n",
    "    return int(idx)\n",
    "\n",
    "def validator(x, key):\n",
    "    valid = True\n",
    "    vmap = torch.ones_like(x)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            tile = int(x[j, i])\n",
    "            \n",
    "            if j-1 >= 0:\n",
    "                if key[tile, int(x[j-1,i])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    "\n",
    "            if j+1 < x.shape[1]:\n",
    "                if key[tile, int(x[j+1,i])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1     \n",
    "\n",
    "            if i-1 >= 0:\n",
    "                if key[tile, int(x[j,i-1])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    "\n",
    "            if i+1 < x.shape[0]:\n",
    "                if key[tile, int(x[j,i+1])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    " \n",
    "\n",
    "    return valid, torch.clamp(vmap, 0, 1)\n",
    "\n",
    "def gen_key(num_tiles, h, w):\n",
    "    map_init = torch.randint(0, num_tiles, (h, w)) # [H, W]\n",
    "    #  Key format: KEY[VALUE, QUERY] -> query is neighbor, value is us tile, returns validity of us given neighbor\n",
    "\n",
    "    key = torch.zeros(( num_tiles, num_tiles))# [1, N, N]\n",
    "    for j in range(w):\n",
    "        for i in range(h):\n",
    "            \n",
    "            if i+1 < h:\n",
    "                key[map_init[i, j], map_init[i+1, j]] = 1 \n",
    "            if i-1 >= 0:\n",
    "                key[map_init[i, j], map_init[i-1, j]] = 1 \n",
    "\n",
    "            if j+1 < w:\n",
    "                key[map_init[i, j], map_init[i, j+1]] = 1 \n",
    "            if j-1 >= 0:\n",
    "                key[map_init[i, j], map_init[i, j-1]] = 1 \n",
    "\n",
    "    return key\n",
    "\n",
    "def gen_seed(num_tiles, height, width):\n",
    "    seed = torch.ones((num_tiles, width, height))\n",
    "    xy = torch.randint(0, height, (2,1))\n",
    "    z = torch.randint(0, num_tiles, (1,1))\n",
    "    seed[:,xy[0], xy[1]] = seed[:,xy[0], xy[1]]*0\n",
    "    seed[z,xy[0], xy[1]] = 1\n",
    "\n",
    "    return seed, xy[1]+xy[0]*width\n",
    "\n",
    "def gen_map(key, h, w, nt):\n",
    "\n",
    "    iter = 0\n",
    "    valid = False\n",
    "\n",
    "    while valid == False:\n",
    "        valid = False\n",
    "        seed, z = gen_seed(nt, h, w)\n",
    "        map_ = actual_wfc(nt, w, h, key, seed, z).squeeze()\n",
    "        val, id = torch.max(map_.flatten(-2,-1),dim=0)\n",
    "        id_map = id.reshape(h,w)\n",
    "        valid, vmap = validator(id_map, key)\n",
    "        iter += 1\n",
    "    \n",
    "    if iter > 10:\n",
    "        print('shit')\n",
    "    \n",
    "    return map_, id_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFUSION CLASS \n",
    "\n",
    "class diffusion():\n",
    "    def __init__(self):\n",
    "        self.num_diffusion_timesteps=1000\n",
    "        scale = 1000 / self.num_diffusion_timesteps\n",
    "        beta_start = scale * 1e-4\n",
    "        beta_end = scale * 0.02\n",
    "        beta = torch.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            self.num_diffusion_timesteps,\n",
    "        )\n",
    "\n",
    "        beta = torch.clamp(beta, 0, 0.999)\n",
    "\n",
    "        self.alpha = 1 - beta\n",
    "        self.self_sqrt_beta = torch.sqrt(beta)\n",
    "        self.alpha_cumulative = torch.cumprod(self.alpha, dim=0)\n",
    "        #alpha_cumulative = torch.clamp(alpha_cumulative, 0, 0.999)\n",
    "        self.sqrt_alpha_cumulative = torch.sqrt(self.alpha_cumulative)\n",
    "        self.one_by_sqrt_alpha = 1. / torch.sqrt(self.alpha)\n",
    "        self.sqrt_one_minus_alpha_cumulative = torch.sqrt(1 - self.alpha_cumulative)\n",
    "\n",
    "\n",
    "    def forward_diffusion(self, x0, timesteps, beta_time, epsilon_prior = 0):\n",
    "\n",
    "        if epsilon_prior.sum() == 0: # We diffuse forward, then check for entropy threshold, then if exceeded we go back in time and idffuse new keys forwar as well with same epsilon\n",
    "            eps = torch.rand_like(x0) \n",
    "        else:\n",
    "            eps = epsilon_prior\n",
    "        \n",
    "        indices = timesteps[beta_time]\n",
    "        mean = self.sqrt_alpha_cumulative[indices] * x0  # Map scaled\n",
    "        std_dev = self.sqrt_one_minus_alpha_cumulative[indices] # Noise scaled\n",
    "        sample  = mean + std_dev * eps # scaled inputs * scaled noise\n",
    "\n",
    "        return sample, eps\n",
    "\n",
    "    def do_diffusion(self, x0, key):\n",
    "        \n",
    "        # x0 is a 3d\n",
    "\n",
    "        noisy_images = x0.squeeze().clone().unsqueeze(0)\n",
    "        xts_threshold = x0.clone()\n",
    "        xts = x0.clone()\n",
    "\n",
    "        specific_timesteps = [0, 10, 50, 100, 150, 200, 250, 300, 400, 600, 800, 999] # This less represents the \"timesteps\" in diffusion and more the \"rate\" of diffusion. \n",
    "        timestep = torch.as_tensor(specific_timesteps, dtype=torch.long)\n",
    "        beta_index = timestep.shape[0]\n",
    "        beta_time = torch.zeros_like(x0)\n",
    "        z = torch.zeros(1)\n",
    "        #beta_time = torch.as_tensor(beta_time, dtype=torch.long)\n",
    "\n",
    "        x_key_mask = self.uncollapse(x0.clone(), key)\n",
    "\n",
    "        diffusing = True\n",
    "        itr = 0\n",
    "        while diffusing:\n",
    "            xPrior = xts\n",
    "            betaPrior = beta_time.clone()\n",
    "\n",
    "            # Take forward diffusion step\n",
    "            xts, eps = self.forward_diffusion(xPrior.clone(), timestep, torch.as_tensor(beta_time, dtype=torch.long), z)\n",
    "\n",
    "            # Update mask according to entropy threshold -> uncollapse valididty \n",
    "            xts_threshold[beta_time >= 3] = 1\n",
    "            x_key_mask = self.uncollapse(xts_threshold, key) \n",
    "            beta_time += torch.ones_like(beta_time) * x_key_mask\n",
    "            beta_time = torch.clamp(beta_time, 0, beta_index-1)\n",
    "\n",
    "            # \"re-perform\" diffusion using retcon'd beta index\n",
    "            xts, _ = self.forward_diffusion(xPrior.clone(), timestep, torch.as_tensor(beta_time, dtype=torch.long), eps)\n",
    "\n",
    "            noisy_images = torch.concat((xts.unsqueeze(0), noisy_images), dim = 0)\n",
    "\n",
    "            itr += 1\n",
    "\n",
    "            if betaPrior.sum() == beta_time.sum():\n",
    "                # Beta time will increase each loop as we march through diffusion, but will stay static when we finish or cannot uncollapse any more\n",
    "                diffusing = False\n",
    "\n",
    "        return noisy_images, itr\n",
    "    \n",
    "    def uncollapse(self, wave_map, key):\n",
    "        diff_map = torch.ones_like(wave_map)\n",
    "\n",
    "        for i in range(wave_map.shape[1]):\n",
    "            for j in range(wave_map.shape[2]):\n",
    "                \n",
    "                if j-1 >= 0:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j-1, i]))#/wave_map[:, j-1, i].sum())\n",
    "\n",
    "                if j+1 < wave_map.shape[1]:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j+1, i]))#/wave_map[:, j+1, i].sum())\n",
    "                        \n",
    "                if i-1 >= 0:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j, i-1]))#/wave_map[:, j, i-1].sum())\n",
    "\n",
    "                if i+1 < wave_map.shape[2]:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j, i+1]))#/wave_map[:, j, i+1].sum())\n",
    "\n",
    "        for k in range(wave_map.shape[0]):\n",
    "            for i in range(wave_map.shape[1]):\n",
    "                for j in range(wave_map.shape[2]):\n",
    "                    if diff_map[k,j,i] >= 4:\n",
    "                        diff_map[k,j,i] = 1\n",
    "                    else:\n",
    "                        diff_map[k,j,i] = 0\n",
    "\n",
    "\n",
    "        return diff_map\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data loading block: Generate key, Generate maps, Diffuse maps\n",
    "\n",
    "\n",
    "\n",
    "df = diffusion()\n",
    "\n",
    "\n",
    "train_size = 300\n",
    "num_tiles = 30\n",
    "height = 3\n",
    "width = 3\n",
    "key = gen_key(num_tiles, 6, 6)\n",
    "key = gen_key(num_tiles, 8, 8)\n",
    "maps_training = torch.zeros(train_size, 50, num_tiles, height, width)\n",
    "diffusion_steps = torch.zeros(train_size)\n",
    "plt.imshow(key.squeeze().numpy())\n",
    "with torch.no_grad():\n",
    "    for m in range(train_size):\n",
    "        x, i_l = gen_map(key, height, width, num_tiles)\n",
    "        \n",
    "        #for d in range(manifold_count):\n",
    "        df_unroll, itr = df.do_diffusion(x, key)\n",
    "        \n",
    "\n",
    "        if itr < 50:\n",
    "            maps_training[m, 0:itr+1, :, :, :] = df_unroll.clone()\n",
    "            diffusion_steps[m] = itr\n",
    "\n",
    "        else:\n",
    "            print('whoops')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has a mean of  tensor(14.0793) and var of  tensor(9.0428)\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 10  and count  1 : 0.014217160245558868 with ratio of  tensor(0.8785)\n",
      "Average correct tiles testing: 5.06 | a mean tile choice of  11.947778  and a variance of 8.612766\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 20  and count  1 : 0.012843895417948564 with ratio of  tensor(0.8911)\n",
      "Average correct tiles testing: 5.33 | a mean tile choice of  11.384444  and a variance of 8.639107\n",
      "\n",
      "\n",
      "Loss for epoch 30  and count  1 : 0.011984205739572644 with ratio of  tensor(0.9063)\n",
      "Average correct tiles testing: 4.74 | a mean tile choice of  11.886667  and a variance of 8.707904\n",
      "\n",
      "\n",
      "Loss for epoch 40  and count  1 : 0.01130332801491022 with ratio of  tensor(0.9133)\n",
      "Average correct tiles testing: 4.9 | a mean tile choice of  11.844444  and a variance of 8.9270735\n",
      "\n",
      "\n",
      "Loss for epoch 50  and count  1 : 0.01070195078306521 with ratio of  tensor(0.9200)\n",
      "Average correct tiles testing: 4.86 | a mean tile choice of  11.256667  and a variance of 8.531339\n",
      "\n",
      "\n",
      "Count increase! Now at 2  with batch size 1\n",
      "Loss for epoch 60  and count  2 : 0.010155222127214075 with ratio of  tensor(0.9226)\n",
      "Average correct tiles testing: 4.73 | a mean tile choice of  11.737779  and a variance of 8.581525\n",
      "\n",
      "\n",
      "Loss for epoch 70  and count  2 : 0.006192401748267002 with ratio of  tensor(0.8648)\n",
      "Average correct tiles testing: 5.0 | a mean tile choice of  11.044445  and a variance of 8.737995\n",
      "\n",
      "\n",
      "Loss for epoch 80  and count  2 : 0.005681074084520029 with ratio of  tensor(0.8793)\n",
      "Average correct tiles testing: 4.56 | a mean tile choice of  11.507777  and a variance of 8.696223\n",
      "\n",
      "\n",
      "Loss for epoch 90  and count  2 : 0.005298082370039386 with ratio of  tensor(0.8907)\n",
      "Average correct tiles testing: 5.02 | a mean tile choice of  10.59  and a variance of 8.204391\n",
      "\n",
      "\n",
      "Loss for epoch 100  and count  2 : 0.004966673916981866 with ratio of  tensor(0.8970)\n",
      "Average correct tiles testing: 4.25 | a mean tile choice of  10.85  and a variance of 8.5791235\n",
      "\n",
      "\n",
      "Loss for epoch 110  and count  2 : 0.004713251640593322 with ratio of  tensor(0.9074)\n",
      "Average correct tiles testing: 4.45 | a mean tile choice of  10.554445  and a variance of 8.364084\n",
      "\n",
      "\n",
      "Loss for epoch 120  and count  2 : 0.00449300559121184 with ratio of  tensor(0.9200)\n",
      "Average correct tiles testing: 4.52 | a mean tile choice of  10.146666  and a variance of 7.9586616\n",
      "\n",
      "\n",
      "Count increase! Now at 3  with batch size 1\n",
      "Loss for epoch 130  and count  3 : 0.004320752382821714 with ratio of  tensor(0.9219)\n",
      "Average correct tiles testing: 4.02 | a mean tile choice of  11.147778  and a variance of 8.3293085\n",
      "\n",
      "\n",
      "Loss for epoch 140  and count  3 : 0.003958053172488387 with ratio of  tensor(0.8463)\n",
      "Average correct tiles testing: 4.72 | a mean tile choice of  10.63111  and a variance of 8.367343\n",
      "\n",
      "\n",
      "Loss for epoch 150  and count  3 : 0.0035880502860527485 with ratio of  tensor(0.8556)\n",
      "Average correct tiles testing: 4.49 | a mean tile choice of  11.671111  and a variance of 8.751674\n",
      "\n",
      "\n",
      "Loss for epoch 160  and count  3 : 0.003327688204590231 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 4.79 | a mean tile choice of  10.781111  and a variance of 8.581359\n",
      "\n",
      "\n",
      "Loss for epoch 170  and count  3 : 0.003135165876786535 with ratio of  tensor(0.8804)\n",
      "Average correct tiles testing: 4.02 | a mean tile choice of  11.677777  and a variance of 8.816762\n",
      "\n",
      "\n",
      "Loss for epoch 180  and count  3 : 0.002964430632807004 with ratio of  tensor(0.8900)\n",
      "Average correct tiles testing: 4.57 | a mean tile choice of  11.29  and a variance of 8.5594015\n",
      "\n",
      "\n",
      "Loss for epoch 190  and count  3 : 0.0028098750781888763 with ratio of  tensor(0.8941)\n",
      "Average correct tiles testing: 4.54 | a mean tile choice of  11.574445  and a variance of 8.691081\n",
      "\n",
      "\n",
      "Loss for epoch 200  and count  3 : 0.002679445106186904 with ratio of  tensor(0.9015)\n",
      "Average correct tiles testing: 4.46 | a mean tile choice of  10.952221  and a variance of 8.728412\n",
      "\n",
      "\n",
      "Loss for epoch 210  and count  3 : 0.0025781125489932797 with ratio of  tensor(0.9104)\n",
      "Average correct tiles testing: 4.61 | a mean tile choice of  11.39  and a variance of 8.86684\n",
      "\n",
      "\n",
      "Loss for epoch 220  and count  3 : 0.002492802027457704 with ratio of  tensor(0.9144)\n",
      "Average correct tiles testing: 4.52 | a mean tile choice of  11.886667  and a variance of 8.758914\n",
      "\n",
      "\n",
      "Loss for epoch 230  and count  3 : 0.0024255518791809058 with ratio of  tensor(0.9185)\n",
      "Average correct tiles testing: 4.39 | a mean tile choice of  11.07111  and a variance of 8.553429\n",
      "\n",
      "\n",
      "Loss for epoch 240  and count  3 : 0.0023558939372499785 with ratio of  tensor(0.9193)\n",
      "Average correct tiles testing: 4.56 | a mean tile choice of  12.081111  and a variance of 8.779076\n",
      "\n",
      "\n",
      "Count increase! Now at 4  with batch size 1\n",
      "Loss for epoch 250  and count  4 : 0.0022956375777721406 with ratio of  tensor(0.9222)\n",
      "Average correct tiles testing: 4.31 | a mean tile choice of  12.738889  and a variance of 8.722186\n",
      "\n",
      "\n",
      "Loss for epoch 260  and count  4 : 0.003706181485710355 with ratio of  tensor(0.7474)\n",
      "Average correct tiles testing: 4.18 | a mean tile choice of  12.450001  and a variance of 8.786371\n",
      "\n",
      "\n",
      "Loss for epoch 270  and count  4 : 0.003441518044952924 with ratio of  tensor(0.7822)\n",
      "Average correct tiles testing: 4.57 | a mean tile choice of  13.334445  and a variance of 8.929888\n",
      "\n",
      "\n",
      "Loss for epoch 280  and count  4 : 0.0032309534839199236 with ratio of  tensor(0.8000)\n",
      "Average correct tiles testing: 4.99 | a mean tile choice of  12.8944435  and a variance of 8.923045\n",
      "\n",
      "\n",
      "Loss for epoch 290  and count  4 : 0.0030585839009533325 with ratio of  tensor(0.8270)\n",
      "Average correct tiles testing: 4.89 | a mean tile choice of  12.386666  and a variance of 8.709707\n",
      "\n",
      "\n",
      "Loss for epoch 300  and count  4 : 0.0029212520056171344 with ratio of  tensor(0.8385)\n",
      "Average correct tiles testing: 4.69 | a mean tile choice of  13.575555  and a variance of 8.63226\n",
      "\n",
      "\n",
      "Loss for epoch 310  and count  4 : 0.002802985843930704 with ratio of  tensor(0.8452)\n",
      "Average correct tiles testing: 4.62 | a mean tile choice of  13.162222  and a variance of 8.833109\n",
      "\n",
      "\n",
      "Loss for epoch 320  and count  4 : 0.0026920908765168863 with ratio of  tensor(0.8530)\n",
      "Average correct tiles testing: 4.78 | a mean tile choice of  12.355556  and a variance of 8.856336\n",
      "\n",
      "\n",
      "Loss for epoch 330  and count  4 : 0.0026058448168138665 with ratio of  tensor(0.8630)\n",
      "Average correct tiles testing: 4.68 | a mean tile choice of  12.692224  and a variance of 8.713063\n",
      "\n",
      "\n",
      "Loss for epoch 340  and count  4 : 0.002528461677332719 with ratio of  tensor(0.8700)\n",
      "Average correct tiles testing: 5.26 | a mean tile choice of  12.622223  and a variance of 8.798117\n",
      "\n",
      "\n",
      "Loss for epoch 350  and count  4 : 0.0024582146575752024 with ratio of  tensor(0.8763)\n",
      "Average correct tiles testing: 4.94 | a mean tile choice of  13.357778  and a variance of 8.933899\n",
      "\n",
      "\n",
      "Loss for epoch 360  and count  4 : 0.002402771102109303 with ratio of  tensor(0.8830)\n",
      "Average correct tiles testing: 4.9 | a mean tile choice of  12.597778  and a variance of 8.828972\n",
      "\n",
      "\n",
      "Loss for epoch 370  and count  4 : 0.002346142091943572 with ratio of  tensor(0.8874)\n",
      "Average correct tiles testing: 5.05 | a mean tile choice of  13.339999  and a variance of 8.816313\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 380  and count  4 : 0.0023005379057334115 with ratio of  tensor(0.8867)\n",
      "Average correct tiles testing: 5.55 | a mean tile choice of  13.016666  and a variance of 8.857242\n",
      "\n",
      "\n",
      "Count increase! Now at 5  with batch size 1\n",
      "Loss for epoch 390  and count  5 : 0.0022571453131968156 with ratio of  tensor(0.8915)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  12.324444  and a variance of 8.756221\n",
      "\n",
      "\n",
      "Loss for epoch 400  and count  5 : 0.004278908890555612 with ratio of  tensor(0.6807)\n",
      "Average correct tiles testing: 5.16 | a mean tile choice of  12.607778  and a variance of 8.84965\n",
      "\n",
      "\n",
      "Loss for epoch 410  and count  5 : 0.004025408150046133 with ratio of  tensor(0.6993)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  14.011111  and a variance of 9.085614\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 420  and count  5 : 0.0037913455253389353 with ratio of  tensor(0.7244)\n",
      "Average correct tiles testing: 5.83 | a mean tile choice of  13.036667  and a variance of 9.095617\n",
      "\n",
      "\n",
      "Loss for epoch 430  and count  5 : 0.0036355068367750695 with ratio of  tensor(0.7333)\n",
      "Average correct tiles testing: 5.6 | a mean tile choice of  13.258888  and a variance of 9.070893\n",
      "\n",
      "\n",
      "Loss for epoch 440  and count  5 : 0.003501754092091384 with ratio of  tensor(0.7319)\n",
      "Average correct tiles testing: 5.42 | a mean tile choice of  13.743334  and a variance of 8.94726\n",
      "\n",
      "\n",
      "Loss for epoch 450  and count  5 : 0.0033872923631376277 with ratio of  tensor(0.7470)\n",
      "Average correct tiles testing: 5.59 | a mean tile choice of  12.825557  and a variance of 8.854155\n",
      "\n",
      "\n",
      "Loss for epoch 460  and count  5 : 0.00326752191176638 with ratio of  tensor(0.7556)\n",
      "Average correct tiles testing: 5.33 | a mean tile choice of  13.084443  and a variance of 9.127827\n",
      "\n",
      "\n",
      "Loss for epoch 470  and count  5 : 0.0031669114978285506 with ratio of  tensor(0.7619)\n",
      "Average correct tiles testing: 5.37 | a mean tile choice of  13.3511095  and a variance of 9.069038\n",
      "\n",
      "\n",
      "Loss for epoch 480  and count  5 : 0.0030660595810816935 with ratio of  tensor(0.7615)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.460001  and a variance of 9.093523\n",
      "\n",
      "\n",
      "Loss for epoch 490  and count  5 : 0.0029737425480076732 with ratio of  tensor(0.7704)\n",
      "Average correct tiles testing: 5.07 | a mean tile choice of  13.384443  and a variance of 9.216288\n",
      "\n",
      "\n",
      "Loss for epoch 500  and count  5 : 0.002880609155787776 with ratio of  tensor(0.7767)\n",
      "Average correct tiles testing: 5.71 | a mean tile choice of  13.325557  and a variance of 9.169049\n",
      "\n",
      "\n",
      "Loss for epoch 510  and count  5 : 0.0027923674482735806 with ratio of  tensor(0.7796)\n",
      "Average correct tiles testing: 5.12 | a mean tile choice of  13.093334  and a variance of 9.108307\n",
      "\n",
      "\n",
      "Loss for epoch 520  and count  5 : 0.002696640848783621 with ratio of  tensor(0.7841)\n",
      "Average correct tiles testing: 5.65 | a mean tile choice of  13.662223  and a variance of 9.268754\n",
      "\n",
      "\n",
      "Loss for epoch 530  and count  5 : 0.002632773009633335 with ratio of  tensor(0.7948)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  13.361111  and a variance of 9.076862\n",
      "\n",
      "\n",
      "Loss for epoch 540  and count  5 : 0.0025556077405538722 with ratio of  tensor(0.8011)\n",
      "Average correct tiles testing: 5.58 | a mean tile choice of  13.86  and a variance of 9.088392\n",
      "\n",
      "\n",
      "Loss for epoch 550  and count  5 : 0.0024821453826734795 with ratio of  tensor(0.8067)\n",
      "Average correct tiles testing: 5.61 | a mean tile choice of  12.901111  and a variance of 8.999692\n",
      "\n",
      "\n",
      "Loss for epoch 560  and count  5 : 0.0024196223036657707 with ratio of  tensor(0.8089)\n",
      "Average correct tiles testing: 5.5 | a mean tile choice of  13.116667  and a variance of 9.356414\n",
      "\n",
      "\n",
      "Loss for epoch 570  and count  5 : 0.002364716379379388 with ratio of  tensor(0.8159)\n",
      "Average correct tiles testing: 5.69 | a mean tile choice of  13.366667  and a variance of 9.1735735\n",
      "\n",
      "\n",
      "Loss for epoch 580  and count  5 : 0.00229897301789606 with ratio of  tensor(0.8181)\n",
      "Average correct tiles testing: 5.71 | a mean tile choice of  12.552222  and a variance of 9.095039\n",
      "\n",
      "\n",
      "Loss for epoch 590  and count  5 : 0.0022509381227428095 with ratio of  tensor(0.8222)\n",
      "Average correct tiles testing: 5.7 | a mean tile choice of  13.178888  and a variance of 9.284167\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 600  and count  5 : 0.0022000690537970513 with ratio of  tensor(0.8304)\n",
      "Average correct tiles testing: 5.84 | a mean tile choice of  13.684444  and a variance of 9.155752\n",
      "\n",
      "\n",
      "Loss for epoch 610  and count  5 : 0.0021617703545295324 with ratio of  tensor(0.8307)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.845557  and a variance of 9.127849\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 620  and count  5 : 0.0021265570426476188 with ratio of  tensor(0.8330)\n",
      "Average correct tiles testing: 5.93 | a mean tile choice of  12.857778  and a variance of 9.157719\n",
      "\n",
      "\n",
      "Loss for epoch 630  and count  5 : 0.0020963573188055307 with ratio of  tensor(0.8378)\n",
      "Average correct tiles testing: 5.75 | a mean tile choice of  13.345556  and a variance of 9.184172\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 640  and count  5 : 0.0020616967457074984 with ratio of  tensor(0.8359)\n",
      "Average correct tiles testing: 5.99 | a mean tile choice of  13.08  and a variance of 9.151118\n",
      "\n",
      "\n",
      "Loss for epoch 650  and count  5 : 0.002034676792876174 with ratio of  tensor(0.8359)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  13.093334  and a variance of 9.205398\n",
      "\n",
      "\n",
      "Loss for epoch 660  and count  5 : 0.002015228175247709 with ratio of  tensor(0.8411)\n",
      "Average correct tiles testing: 5.15 | a mean tile choice of  13.091111  and a variance of 9.01807\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 670  and count  5 : 0.0019965036275486152 with ratio of  tensor(0.8422)\n",
      "Average correct tiles testing: 6.03 | a mean tile choice of  13.426667  and a variance of 9.071204\n",
      "\n",
      "\n",
      "Loss for epoch 680  and count  5 : 0.001981088851656144 with ratio of  tensor(0.8444)\n",
      "Average correct tiles testing: 5.29 | a mean tile choice of  13.451111  and a variance of 8.917282\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 690  and count  5 : 0.0019654411206526372 with ratio of  tensor(0.8478)\n",
      "Average correct tiles testing: 6.14 | a mean tile choice of  12.704445  and a variance of 9.022873\n",
      "\n",
      "\n",
      "Loss for epoch 700  and count  5 : 0.0019540934603234444 with ratio of  tensor(0.8552)\n",
      "Average correct tiles testing: 5.28 | a mean tile choice of  14.470001  and a variance of 9.230028\n",
      "\n",
      "\n",
      "Loss for epoch 710  and count  5 : 0.0019437967333942653 with ratio of  tensor(0.8556)\n",
      "Average correct tiles testing: 6.02 | a mean tile choice of  13.286668  and a variance of 9.188482\n",
      "\n",
      "\n",
      "Loss for epoch 720  and count  5 : 0.0019336293201195076 with ratio of  tensor(0.8537)\n",
      "Average correct tiles testing: 5.65 | a mean tile choice of  13.798889  and a variance of 9.060407\n",
      "\n",
      "\n",
      "Loss for epoch 730  and count  5 : 0.0019202249427326024 with ratio of  tensor(0.8519)\n",
      "Average correct tiles testing: 5.52 | a mean tile choice of  14.706665  and a variance of 9.067694\n",
      "\n",
      "\n",
      "Loss for epoch 740  and count  5 : 0.0019116569555869016 with ratio of  tensor(0.8522)\n",
      "Average correct tiles testing: 5.63 | a mean tile choice of  13.587778  and a variance of 9.265906\n",
      "\n",
      "\n",
      "Loss for epoch 750  and count  5 : 0.0019030541597749107 with ratio of  tensor(0.8522)\n",
      "Average correct tiles testing: 5.43 | a mean tile choice of  13.796668  and a variance of 9.432832\n",
      "\n",
      "\n",
      "Loss for epoch 760  and count  5 : 0.0018950642229174264 with ratio of  tensor(0.8530)\n",
      "Average correct tiles testing: 5.61 | a mean tile choice of  13.605556  and a variance of 8.975333\n",
      "\n",
      "\n",
      "Loss for epoch 770  and count  5 : 0.001886678785958793 with ratio of  tensor(0.8548)\n",
      "Average correct tiles testing: 5.46 | a mean tile choice of  12.777779  and a variance of 9.215845\n",
      "\n",
      "\n",
      "Loss for epoch 780  and count  5 : 0.0018748913119391848 with ratio of  tensor(0.8567)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  12.816668  and a variance of 9.442913\n",
      "\n",
      "\n",
      "Loss for epoch 790  and count  5 : 0.001866823542319859 with ratio of  tensor(0.8548)\n",
      "Average correct tiles testing: 5.8 | a mean tile choice of  13.51111  and a variance of 9.238264\n",
      "\n",
      "\n",
      "Loss for epoch 800  and count  5 : 0.0018591055800789035 with ratio of  tensor(0.8563)\n",
      "Average correct tiles testing: 5.62 | a mean tile choice of  14.7288885  and a variance of 8.940084\n",
      "\n",
      "\n",
      "Loss for epoch 810  and count  5 : 0.001848945134455183 with ratio of  tensor(0.8593)\n",
      "Average correct tiles testing: 5.34 | a mean tile choice of  13.911111  and a variance of 9.097665\n",
      "\n",
      "\n",
      "Loss for epoch 820  and count  5 : 0.0018388788234248448 with ratio of  tensor(0.8574)\n",
      "Average correct tiles testing: 5.62 | a mean tile choice of  13.403334  and a variance of 9.114114\n",
      "\n",
      "\n",
      "Loss for epoch 830  and count  5 : 0.001830638662892549 with ratio of  tensor(0.8619)\n",
      "Average correct tiles testing: 5.34 | a mean tile choice of  13.414445  and a variance of 9.111377\n",
      "\n",
      "\n",
      "Loss for epoch 840  and count  5 : 0.0018227739377956217 with ratio of  tensor(0.8648)\n",
      "Average correct tiles testing: 5.76 | a mean tile choice of  12.854445  and a variance of 9.153306\n",
      "\n",
      "\n",
      "Loss for epoch 850  and count  5 : 0.001813824371395943 with ratio of  tensor(0.8652)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.62  and a variance of 9.286556\n",
      "\n",
      "\n",
      "Loss for epoch 860  and count  5 : 0.0018063039078454798 with ratio of  tensor(0.8652)\n",
      "Average correct tiles testing: 5.42 | a mean tile choice of  13.334445  and a variance of 9.275265\n",
      "\n",
      "\n",
      "Loss for epoch 870  and count  5 : 0.001798790319201847 with ratio of  tensor(0.8644)\n",
      "Average correct tiles testing: 5.58 | a mean tile choice of  13.544445  and a variance of 8.889187\n",
      "\n",
      "\n",
      "Loss for epoch 880  and count  5 : 0.0017913998746856427 with ratio of  tensor(0.8685)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  13.585555  and a variance of 9.270829\n",
      "\n",
      "\n",
      "Loss for epoch 890  and count  5 : 0.0017831356178309458 with ratio of  tensor(0.8730)\n",
      "Average correct tiles testing: 5.48 | a mean tile choice of  13.527778  and a variance of 9.235075\n",
      "\n",
      "\n",
      "Loss for epoch 900  and count  5 : 0.0017756638664286584 with ratio of  tensor(0.8704)\n",
      "Average correct tiles testing: 5.55 | a mean tile choice of  13.042223  and a variance of 9.158231\n",
      "\n",
      "\n",
      "Loss for epoch 910  and count  5 : 0.0017682516883360223 with ratio of  tensor(0.8696)\n",
      "Average correct tiles testing: 6.08 | a mean tile choice of  13.176667  and a variance of 9.201549\n",
      "\n",
      "\n",
      "Loss for epoch 920  and count  5 : 0.0017620560360956006 with ratio of  tensor(0.8707)\n",
      "Average correct tiles testing: 5.87 | a mean tile choice of  13.017779  and a variance of 9.14386\n",
      "\n",
      "\n",
      "Loss for epoch 930  and count  5 : 0.0017559715630098556 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 5.79 | a mean tile choice of  13.455555  and a variance of 9.21405\n",
      "\n",
      "\n",
      "Loss for epoch 940  and count  5 : 0.0017499590624356642 with ratio of  tensor(0.8726)\n",
      "Average correct tiles testing: 5.97 | a mean tile choice of  13.661111  and a variance of 9.219522\n",
      "\n",
      "\n",
      "Loss for epoch 950  and count  5 : 0.0017443689587526023 with ratio of  tensor(0.8696)\n",
      "Average correct tiles testing: 5.47 | a mean tile choice of  13.373333  and a variance of 8.896755\n",
      "\n",
      "\n",
      "Loss for epoch 960  and count  5 : 0.0017389342262564848 with ratio of  tensor(0.8741)\n",
      "Average correct tiles testing: 5.54 | a mean tile choice of  13.543332  and a variance of 9.260556\n",
      "\n",
      "\n",
      "Loss for epoch 970  and count  5 : 0.0017348468327933611 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 5.66 | a mean tile choice of  12.946667  and a variance of 9.330492\n",
      "\n",
      "\n",
      "Loss for epoch 980  and count  5 : 0.0017296831115769843 with ratio of  tensor(0.8737)\n",
      "Average correct tiles testing: 5.88 | a mean tile choice of  13.935555  and a variance of 9.100479\n",
      "\n",
      "\n",
      "Loss for epoch 990  and count  5 : 0.001724725477785493 with ratio of  tensor(0.8730)\n",
      "Average correct tiles testing: 5.53 | a mean tile choice of  13.731111  and a variance of 9.121807\n",
      "\n",
      "\n",
      "Loss for epoch 1000  and count  5 : 0.0017223719397831399 with ratio of  tensor(0.8715)\n",
      "Average correct tiles testing: 5.44 | a mean tile choice of  13.541111  and a variance of 9.090029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "\n",
    "epochs = 1000\n",
    "width = width = 3 #map_w\n",
    "height = height = 3 #map_h\n",
    "num_tiles = num_tiles\n",
    "diffusion_steps_GRU = 13\n",
    "steps = 8\n",
    "step_size = 5\n",
    "kernel_size = 3\n",
    "l_sum_np = 0\n",
    "batch_size = 1\n",
    "loss = 0\n",
    "count = 1\n",
    "threshold = 0.92\n",
    "test_len = 100\n",
    "prev_max = 4.5 # Initial threshold before we start dropping the LR. We don't want to drop it aggresively until at least half the test tiles placed are valid\n",
    "\n",
    "curriculum = True\n",
    "switch = True\n",
    "\n",
    "index_list = np.arange(train_size)\n",
    "id_list = np.arange(width)\n",
    "index = np.arange(width*height)\n",
    "\n",
    "index_even = np.arange(5)*2\n",
    "index_odd = np.arange(4)*2+1\n",
    "\n",
    "#gru = GRU_WFC(num_tiles, 0, height, width, diffusion_steps_GRU, kernel_size, bias_sca+le = 0.25, deep = False)\n",
    "gru = GRU_WFC_2(num_tiles)\n",
    "device = 'cuda:0'\n",
    "#gru.to(device)\n",
    "\n",
    "loss_func =  nn.MSELoss() # nn.L1Loss() #\n",
    "l_kl = torch.nn.KLDivLoss(reduction=\"batchmean\", log_target = True)\n",
    "lbce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#loss_l1 = nn.L1Loss()\n",
    "optimizer = torch.optim.NAdam(gru.parameters(), lr = 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.79)\n",
    "\n",
    "map_ = torch.zeros(train_size, num_tiles, height, width)\n",
    "for ii in range(train_size):\n",
    "    map_[ii] = maps_training[ii, int(diffusion_steps[ii]), :, :, :]\n",
    "\n",
    "\n",
    "_, id_set = torch.max(map_, dim = 1)\n",
    "\n",
    "va, m = (torch.var_mean(id_set.float(), 0))\n",
    "print('The training dataset has a mean tile choice of ', m.mean(),'with a mean std of', va.mean().sqrt())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    v_ratio = 0\n",
    "    np.random.shuffle(index_list)\n",
    "\n",
    "    for i1 in range(train_size):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            id = index_list[i1]\n",
    "            dfinal = diffusion_steps[id]\n",
    "            h_init = maps_training[id, 0:int(dfinal)+1]\n",
    "\n",
    "        if curriculum:\n",
    "            # Replaces a random tile with a noise vector. Curriculum adds another instance of noise when [% valid choices > 0.9]\n",
    "            np.random.shuffle(index)\n",
    "            h_init = h_init.requires_grad_(False)\n",
    "            fmap = h_init[int(dfinal)].squeeze().clone()\n",
    "\n",
    "            for k in range(len(index_even)):\n",
    "                id_lin = index_even[k]\n",
    "                with torch.no_grad():\n",
    "                    id_x = id_lin % width\n",
    "                    id_y = id_lin // height\n",
    "                    mask = h_init[0,:,id_x,id_y].cpu().clone()\n",
    "                    fmap[:,id_x,id_y] = fmap[:,id_x,id_y]*0 + mask\n",
    "\n",
    "            for k in range(count-1):\n",
    "                id_lin = index_odd[k]\n",
    "                with torch.no_grad():\n",
    "                    id_x = id_lin % width\n",
    "                    id_y = id_lin // height\n",
    "                    mask = h_init[0,:,id_x,id_y].cpu().clone()\n",
    "                    fmap[:,id_x,id_y] = fmap[:,id_x,id_y]*0 + mask\n",
    "            \n",
    "                    \n",
    "            h_init = h_init.requires_grad_(True)\n",
    "            fmap = fmap.unsqueeze(0)\n",
    "\n",
    "        map_wfc_retained = gru.forward(fmap, key, 10, False, 0).squeeze() #int(dfinal[m]), training = False).squeeze()\n",
    "        lv = loss_func(map_wfc_retained, h_init[int(dfinal)]) / count\n",
    "        loss += lv\n",
    "\n",
    "        # Summing valid tiles\n",
    "        with torch.no_grad():\n",
    "            _, id_pred = torch.max(map_wfc_retained.clone().cpu().detach(), dim = 0)\n",
    "            _, v = validator(id_pred, key)\n",
    "            v_ratio += torch.clamp(v, 0, 1).sum()/(height*width)\n",
    "\n",
    "        l_sum_np += lv.clone().cpu().detach().numpy()\n",
    "        if (batch_size == 1) or (i1%batch_size == 0 and i1 > 0):\n",
    "            loss = loss/batch_size\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            loss = 0\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        vsum = torch.zeros(test_len, height, width)\n",
    "        idsum = torch.zeros(test_len, height, width)\n",
    "        for k in range(test_len):\n",
    "            h_noise = torch.rand_like(h_init[0].clone().squeeze().unsqueeze(0))\n",
    "            map_wfc_noise = gru.forward(h_noise, key, 10, False, 0).squeeze()\n",
    "            _, id_noise = torch.max(map_wfc_noise, dim = 0)\n",
    "\n",
    "            _, v = validator(id_noise, key)\n",
    "            idsum[k] = id_noise\n",
    "            vsum[k] = v\n",
    "\n",
    "            \n",
    "        va, me = torch.var_mean(idsum, dim = 0)\n",
    "        print()\n",
    "        if v_ratio / train_size > threshold and epoch > 20:\n",
    "            count += 1\n",
    "            scheduler.step()\n",
    "            #batch_size += 1\n",
    "            if count >= 4:\n",
    "                threshold = 0.89\n",
    "\n",
    "            if count > 5: #width*height:\n",
    "                count = 5 # width*height\n",
    "                test_len = 1000\n",
    "                if switch:\n",
    "                    print('We made it to 9 randoms!')\n",
    "                    switch = False\n",
    "\n",
    "            print('Count increase! Now at', count, ' with batch size', batch_size)\n",
    "        if vsum.sum().numpy()/test_len > prev_max:\n",
    "                prev_max = vsum.sum().numpy()/test_len\n",
    "                print('Optim lr step')\n",
    "                scheduler.step()\n",
    "                \n",
    "        print('Loss for epoch', epoch+1,' and count ', count, ':', l_sum_np / (train_size), 'with ratio of ', v_ratio / train_size)\n",
    "        print('Average correct tiles testing:', vsum.sum().numpy()/test_len, '| a mean tile choice of ', me.mean().numpy(), ' and a variance of', va.mean().sqrt().numpy())     \n",
    "        print()\n",
    "    l_sum_np = 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  tensor(20.5287)  and variance  tensor(7.1775)\n",
      "Total valid points tensor(267767)  out of 360000  =  tensor(0.7438)  percent correctness\n"
     ]
    }
   ],
   "source": [
    "# testing block\n",
    "\n",
    "v_sum = 0\n",
    "width = 60\n",
    "height = width\n",
    "g = 0\n",
    "#\n",
    "gg = 100\n",
    "id_nl = torch.zeros((gg, height, width))\n",
    "with torch.no_grad():\n",
    "    for it in range(1):\n",
    "        for k in range(gg):\n",
    "            \n",
    "            h_noise = torch.rand((1, num_tiles, height, width))\n",
    "            map_wfc_noise = gru.forward(h_noise, key, 30, False, 0).squeeze()\n",
    "            \n",
    "            _, id_noise = torch.max(map_wfc_noise, dim = 0)\n",
    "\n",
    "            id_nl[k] = id_noise.squeeze()\n",
    "\n",
    "            valid, v = validator(id_noise, key)\n",
    "            v = torch.clamp(v, 0, 1).sum()\n",
    "            v_sum += v\n",
    "\n",
    "    \n",
    "var, me= torch.var_mean(id_nl, dim=0)\n",
    "print('mean of',me.mean().numpy(), ' and a mean std ', var.mean().sqrt().numpy())\n",
    "print('Total valid points', v_sum, ' out of', gg*width*height,' = ', v_sum/(gg*(width*height)),' percent correctness')\n",
    "\n",
    "# https://arxiv.org/pdf/2102.09672.pdf\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
