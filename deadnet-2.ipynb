{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU V2 param net\n",
    "\n",
    "class GRU_WFC_2(nn.Module):\n",
    "    def __init__(self,tile_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_tile = tile_num\n",
    "        self.inp_channels = tile_num\n",
    "        self.op_channels = tile_num\n",
    "        self.k_size = 3\n",
    "        self.pad_size = 2\n",
    "        self.p_size = self.k_size//2\n",
    "        self.bias_scale = 0.25\n",
    "\n",
    "        expansion_ratio = 3\n",
    "\n",
    "        self.inter_cv1 = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv2 = nn.Conv2d(self.num_tile, self.num_tile//2, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv3 = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "        self.inter_cv4 = nn.Conv2d(self.num_tile//2, self.num_tile, (1,self.k_size), padding=(0,self.p_size))\n",
    "\n",
    "        self.inter_ch1 = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch2 = nn.Conv2d(self.num_tile, self.num_tile//2, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch3 = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "        self.inter_ch4 = nn.Conv2d(self.num_tile//2, self.num_tile, (self.k_size,1), padding=(self.p_size,0))\n",
    "\n",
    "        self.inter_skip = nn.Conv2d(self.num_tile*2, self.num_tile, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate_e = nn.Conv2d(self.num_tile, self.num_tile*expansion_ratio, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate_r = nn.Conv2d(self.num_tile*expansion_ratio, self.num_tile, self.k_size, 1, self.p_size)\n",
    "        self.inter_skip_gate = nn.Conv2d(self.num_tile, self.num_tile, self.k_size, 1, self.p_size)\n",
    "\n",
    "        self.sigma = torch.nn.Sigmoid()\n",
    "        self.phi = torch.nn.Tanh()\n",
    "        self.lRel = torch.nn.LeakyReLU(0.2)\n",
    "        self.pad = torch.nn.ZeroPad2d(1)\n",
    "\n",
    "       \n",
    "    def forward(self, h, key, iter, training, context_vector):\n",
    "\n",
    "        for i in range(iter):\n",
    "\n",
    "            h  = self.deep_collapse(h)\n",
    "\n",
    "            if training:\n",
    "                if iter == 0:  \n",
    "                    h_ret = h.clone().unsqueeze(1)\n",
    "                else:  \n",
    "                    h_ret = torch.concat((h_ret, h.clone().unsqueeze(1)), dim = 1)\n",
    "\n",
    "        if training:  \n",
    "            return h_ret\n",
    "        else:  \n",
    "            return h\n",
    "\n",
    "    def deep_collapse(self, h):\n",
    "    \n",
    "        xskipv = h.clone()\n",
    "        xskiph = h.clone()\n",
    "        \n",
    "        v1 = self.inter_cv1(xskipv)\n",
    "        v2 = self.phi(self.inter_cv3(v1))\n",
    "        v3 = self.lRel(self.inter_cv2(xskipv))\n",
    "        v4 = self.sigma(self.inter_cv4(v3))\n",
    "        xskipv = xskipv * (1 - v4) + v2 * self.bias_scale\n",
    "\n",
    "        h1 = self.inter_ch1(xskiph)\n",
    "        h2 = self.phi(self.inter_ch3(h1))\n",
    "        h3 = self.lRel(self.inter_ch2(xskiph))\n",
    "        h4 = self.sigma(self.inter_ch4(h3))\n",
    "        xskiph = xskiph * (1 - h4) + h2 * self.bias_scale\n",
    "\n",
    "        xskip = torch.concat((xskipv, xskiph), dim=1)\n",
    "        xskip = self.sigma(self.inter_skip(xskip))\n",
    "        gate = self.sigma(self.inter_skip_gate(h))\n",
    "        h = h * (1 - gate) + self.phi(xskip) * gate \n",
    "\n",
    "        return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL WFC\n",
    "\n",
    "def actual_wfc(tile_space, width, height, key, seed, z):\n",
    "\n",
    "    wave_map = torch.ones((tile_space, width, height))\n",
    "    collapse_index = torch.zeros(width * height)\n",
    "\n",
    "    #if seed != None:\n",
    "    wave_map = wave_map * seed\n",
    "    collapse_index[z] = 1\n",
    "\n",
    "    wave_map = diffuse(wave_map, z//width, z%width, key, width, height)\n",
    "\n",
    "    key = key\n",
    "    collapsed = False\n",
    "    count = 0\n",
    "    if 1:\n",
    "        while not collapsed:\n",
    "            id_lin = choose(wave_map, collapse_index)\n",
    "            if id_lin >= 0:\n",
    "                cx = id_lin % width\n",
    "                cy = id_lin // width\n",
    "\n",
    "                wave_vec = wave_map[:,cy, cx].squeeze() #key_return(wave_map, cy, cx, height, width, key, 4)\n",
    "                tile = collapse(wave_vec)\n",
    "\n",
    "                wave_map[:, cy, cx] = tile\n",
    "                wave_map = diffuse(wave_map, cy, cx, key, width, height)\n",
    "                \n",
    "                collapse_index[cx + cy * width] = 1\n",
    "\n",
    "                if collapse_index.sum() == width * height or count > width*height + 10:\n",
    "                    collapsed = True\n",
    "                    if count > width*height + 10:\n",
    "                        print('out of time')\n",
    "                    break\n",
    "\n",
    "                count += 1\n",
    "\n",
    "    return wave_map\n",
    "\n",
    "def diffuse(map_, cy, cx, k, w, h):\n",
    "    cy = int(cy)\n",
    "    cx = int(cx)\n",
    "    vec = map_[:, cy, cx].unsqueeze(-1)\n",
    "\n",
    "    if cy-1 >= 0:\n",
    "        map_[:, cy-1,cx] = map_[:, cy-1,cx] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cy+1 < h:\n",
    "        map_[:, cy+1,cx] = map_[:, cy+1,cx] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cx-1 >= 0:\n",
    "        map_[:, cy, cx-1] = map_[:, cy, cx-1] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "    if cx+1 < w:\n",
    "        map_[:, cy, cx+1] = map_[:, cy, cx+1] * (torch.matmul(k, vec).squeeze())#.unsqueeze(-1)\n",
    "\n",
    "    return map_\n",
    "\n",
    "def collapse(x): \n",
    "    # X is current wavespace legality key\n",
    "    \n",
    "    probability = torch.softmax(torch.rand_like(x), dim=0) #*torch.softmax(freq, dim=0)\n",
    "    likelihood = x * probability #torch.matmul(key.T, probability.T)\n",
    "    _, tile_choice = torch.max(likelihood, dim=0)\n",
    "    x_collapse = torch.zeros_like(x)\n",
    "    x_collapse[tile_choice] = 1\n",
    "\n",
    "    return x_collapse\n",
    "    \n",
    "\n",
    "def choose(map_, collapse_list):\n",
    "    x_sum = torch.sum(map_,dim=0)\n",
    "    x_sumf = x_sum.flatten()\n",
    "    v, id = x_sumf.sort()\n",
    "    idx = -1\n",
    "\n",
    "    for k in range((v.shape[0])):\n",
    "        if collapse_list[id[k]] == 0:\n",
    "            idx = id[k]\n",
    "            break\n",
    "\n",
    "    return int(idx)\n",
    "\n",
    "def validator(x, key):\n",
    "    valid = True\n",
    "    vmap = torch.ones_like(x)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            tile = int(x[j, i])\n",
    "            \n",
    "            if j-1 >= 0:\n",
    "                if key[tile, int(x[j-1,i])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    "\n",
    "            if j+1 < x.shape[1]:\n",
    "                if key[tile, int(x[j+1,i])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1     \n",
    "\n",
    "            if i-1 >= 0:\n",
    "                if key[tile, int(x[j,i-1])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    "\n",
    "            if i+1 < x.shape[0]:\n",
    "                if key[tile, int(x[j,i+1])] == 0:\n",
    "                    valid = False\n",
    "                    vmap[j,i] -= 1\n",
    " \n",
    "\n",
    "    return valid, torch.clamp(vmap, 0, 1)\n",
    "\n",
    "def gen_key(num_tiles, h, w):\n",
    "    map_init = torch.randint(0, num_tiles, (h, w)) # [H, W]\n",
    "    #  Key format: KEY[VALUE, QUERY] -> query is neighbor, value is us tile, returns validity of us given neighbor\n",
    "\n",
    "    key = torch.zeros(( num_tiles, num_tiles))# [1, N, N]\n",
    "    for j in range(w):\n",
    "        for i in range(h):\n",
    "            \n",
    "            if i+1 < h:\n",
    "                key[map_init[i, j], map_init[i+1, j]] = 1 \n",
    "            if i-1 >= 0:\n",
    "                key[map_init[i, j], map_init[i-1, j]] = 1 \n",
    "\n",
    "            if j+1 < w:\n",
    "                key[map_init[i, j], map_init[i, j+1]] = 1 \n",
    "            if j-1 >= 0:\n",
    "                key[map_init[i, j], map_init[i, j-1]] = 1 \n",
    "\n",
    "    return key\n",
    "\n",
    "def gen_seed(num_tiles, height, width):\n",
    "    seed = torch.ones((num_tiles, width, height))\n",
    "    xy = torch.randint(0, height, (2,1))\n",
    "    z = torch.randint(0, num_tiles, (1,1))\n",
    "    seed[:,xy[0], xy[1]] = seed[:,xy[0], xy[1]]*0\n",
    "    seed[z,xy[0], xy[1]] = 1\n",
    "\n",
    "    return seed, xy[1]+xy[0]*width\n",
    "\n",
    "def gen_map(key, h, w, nt):\n",
    "\n",
    "    iter = 0\n",
    "    valid = False\n",
    "\n",
    "    while valid == False:\n",
    "        valid = False\n",
    "        seed, z = gen_seed(nt, h, w)\n",
    "        map_ = actual_wfc(nt, w, h, key, seed, z).squeeze()\n",
    "        val, id = torch.max(map_.flatten(-2,-1),dim=0)\n",
    "        id_map = id.reshape(h,w)\n",
    "        valid, vmap = validator(id_map, key)\n",
    "        iter += 1\n",
    "    \n",
    "    return map_, id_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFUSION CLASS \n",
    "\n",
    "\"\"\"\n",
    "This class is still used for generating the input noise for each training map, though no actuall diffusion method is used in training right now\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class diffusion():\n",
    "    def __init__(self):\n",
    "        self.num_diffusion_timesteps=1000\n",
    "        scale = 1000 / self.num_diffusion_timesteps\n",
    "        beta_start = scale * 1e-4\n",
    "        beta_end = scale * 0.02\n",
    "        beta = torch.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            self.num_diffusion_timesteps,\n",
    "        )\n",
    "\n",
    "        beta = torch.clamp(beta, 0, 0.999)\n",
    "\n",
    "        self.alpha = 1 - beta\n",
    "        self.self_sqrt_beta = torch.sqrt(beta)\n",
    "        self.alpha_cumulative = torch.cumprod(self.alpha, dim=0)\n",
    "        #alpha_cumulative = torch.clamp(alpha_cumulative, 0, 0.999)\n",
    "        self.sqrt_alpha_cumulative = torch.sqrt(self.alpha_cumulative)\n",
    "        self.one_by_sqrt_alpha = 1. / torch.sqrt(self.alpha)\n",
    "        self.sqrt_one_minus_alpha_cumulative = torch.sqrt(1 - self.alpha_cumulative)\n",
    "\n",
    "\n",
    "    def forward_diffusion(self, x0, timesteps, beta_time, epsilon_prior = 0):\n",
    "\n",
    "        if epsilon_prior.sum() == 0: # We diffuse forward, then check for entropy threshold, then if exceeded we go back in time and idffuse new keys forwar as well with same epsilon\n",
    "            eps = torch.rand_like(x0) \n",
    "        else:\n",
    "            eps = epsilon_prior\n",
    "        \n",
    "        indices = timesteps[beta_time]\n",
    "        mean = self.sqrt_alpha_cumulative[indices] * x0  # Map scaled\n",
    "        std_dev = self.sqrt_one_minus_alpha_cumulative[indices] # Noise scaled\n",
    "        sample  = mean + std_dev * eps # scaled inputs * scaled noise\n",
    "\n",
    "        return sample, eps\n",
    "\n",
    "    def do_diffusion(self, x0, key):\n",
    "        \n",
    "        # x0 is a 3d\n",
    "\n",
    "        noisy_images = x0.squeeze().clone().unsqueeze(0)\n",
    "        xts_threshold = x0.clone()\n",
    "        xts = x0.clone()\n",
    "\n",
    "        specific_timesteps = [0, 10, 50, 100, 150, 200, 250, 300, 400, 600, 800, 999] # This less represents the \"timesteps\" in diffusion and more the \"rate\" of diffusion. \n",
    "        timestep = torch.as_tensor(specific_timesteps, dtype=torch.long)\n",
    "        beta_index = timestep.shape[0]\n",
    "        beta_time = torch.zeros_like(x0)\n",
    "        z = torch.zeros(1)\n",
    "        #beta_time = torch.as_tensor(beta_time, dtype=torch.long)\n",
    "\n",
    "        x_key_mask = self.uncollapse(x0.clone(), key)\n",
    "\n",
    "        diffusing = True\n",
    "        itr = 0\n",
    "        while diffusing:\n",
    "            xPrior = xts\n",
    "            betaPrior = beta_time.clone()\n",
    "\n",
    "            # Take forward diffusion step\n",
    "            xts, eps = self.forward_diffusion(xPrior.clone(), timestep, torch.as_tensor(beta_time, dtype=torch.long), z)\n",
    "\n",
    "            # Update mask according to entropy threshold -> uncollapse valididty \n",
    "            xts_threshold[beta_time >= 3] = 1\n",
    "            x_key_mask = self.uncollapse(xts_threshold, key) \n",
    "            beta_time += torch.ones_like(beta_time) * x_key_mask\n",
    "            beta_time = torch.clamp(beta_time, 0, beta_index-1)\n",
    "\n",
    "            # \"re-perform\" diffusion using retcon'd beta index\n",
    "            xts, _ = self.forward_diffusion(xPrior.clone(), timestep, torch.as_tensor(beta_time, dtype=torch.long), eps)\n",
    "\n",
    "            noisy_images = torch.concat((xts.unsqueeze(0), noisy_images), dim = 0)\n",
    "\n",
    "            itr += 1\n",
    "\n",
    "            if betaPrior.sum() == beta_time.sum():\n",
    "                # Beta time will increase each loop as we march through diffusion, but will stay static when we finish or cannot uncollapse any more\n",
    "                diffusing = False\n",
    "\n",
    "        return noisy_images, itr\n",
    "    \n",
    "    def uncollapse(self, wave_map, key):\n",
    "        diff_map = torch.ones_like(wave_map)\n",
    "\n",
    "        for i in range(wave_map.shape[1]):\n",
    "            for j in range(wave_map.shape[2]):\n",
    "                \n",
    "                if j-1 >= 0:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j-1, i]))#/wave_map[:, j-1, i].sum())\n",
    "\n",
    "                if j+1 < wave_map.shape[1]:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j+1, i]))#/wave_map[:, j+1, i].sum())\n",
    "                        \n",
    "                if i-1 >= 0:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j, i-1]))#/wave_map[:, j, i-1].sum())\n",
    "\n",
    "                if i+1 < wave_map.shape[2]:\n",
    "                    diff_map[:,j,i] += diff_map[:,j,i]*(torch.matmul(key, wave_map[:, j, i+1]))#/wave_map[:, j, i+1].sum())\n",
    "\n",
    "        for k in range(wave_map.shape[0]):\n",
    "            for i in range(wave_map.shape[1]):\n",
    "                for j in range(wave_map.shape[2]):\n",
    "                    if diff_map[k,j,i] >= 4:\n",
    "                        diff_map[k,j,i] = 1\n",
    "                    else:\n",
    "                        diff_map[k,j,i] = 0\n",
    "\n",
    "\n",
    "        return diff_map\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/9_0p0ctd5cd5q3f8lhpbzpc40000gn/T/ipykernel_12974/1638094077.py:12: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  wave_map = diffuse(wave_map, z//width, z%width, key, width, height)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data loading block: Generate key, Generate maps, Diffuse maps\n",
    "\n",
    "\n",
    "\n",
    "df = diffusion()\n",
    "\n",
    "\n",
    "train_size = 100\n",
    "num_tiles = 30\n",
    "height = 3\n",
    "width = 3\n",
    "key = gen_key(num_tiles, 6, 6)\n",
    "key = gen_key(num_tiles, 8, 8)\n",
    "maps_training = torch.zeros(train_size, 50, num_tiles, height, width)\n",
    "diffusion_steps = torch.zeros(train_size)\n",
    "plt.imshow(key.squeeze().numpy())\n",
    "plt.title('Key validity matrix')\n",
    "plt.colorbar()\n",
    "with torch.no_grad():\n",
    "    for m in range(train_size):\n",
    "        x, i_l = gen_map(key, height, width, num_tiles)\n",
    "        \n",
    "        #for d in range(manifold_count):\n",
    "        df_unroll, itr = df.do_diffusion(x, key)\n",
    "        \n",
    "\n",
    "        if itr < 50:\n",
    "            maps_training[m, 0:itr+1, :, :, :] = df_unroll.clone()\n",
    "            diffusion_steps[m] = itr\n",
    "\n",
    "        else:\n",
    "            print('whoops')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has a mean of  tensor(14.0793) and var of  tensor(9.0428)\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 10  and count  1 : 0.014217160245558868 with ratio of  tensor(0.8785)\n",
      "Average correct tiles testing: 5.06 | a mean tile choice of  11.947778  and a variance of 8.612766\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 20  and count  1 : 0.012843895417948564 with ratio of  tensor(0.8911)\n",
      "Average correct tiles testing: 5.33 | a mean tile choice of  11.384444  and a variance of 8.639107\n",
      "\n",
      "\n",
      "Loss for epoch 30  and count  1 : 0.011984205739572644 with ratio of  tensor(0.9063)\n",
      "Average correct tiles testing: 4.74 | a mean tile choice of  11.886667  and a variance of 8.707904\n",
      "\n",
      "\n",
      "Loss for epoch 40  and count  1 : 0.01130332801491022 with ratio of  tensor(0.9133)\n",
      "Average correct tiles testing: 4.9 | a mean tile choice of  11.844444  and a variance of 8.9270735\n",
      "\n",
      "\n",
      "Loss for epoch 50  and count  1 : 0.01070195078306521 with ratio of  tensor(0.9200)\n",
      "Average correct tiles testing: 4.86 | a mean tile choice of  11.256667  and a variance of 8.531339\n",
      "\n",
      "\n",
      "Count increase! Now at 2  with batch size 1\n",
      "Loss for epoch 60  and count  2 : 0.010155222127214075 with ratio of  tensor(0.9226)\n",
      "Average correct tiles testing: 4.73 | a mean tile choice of  11.737779  and a variance of 8.581525\n",
      "\n",
      "\n",
      "Loss for epoch 70  and count  2 : 0.006192401748267002 with ratio of  tensor(0.8648)\n",
      "Average correct tiles testing: 5.0 | a mean tile choice of  11.044445  and a variance of 8.737995\n",
      "\n",
      "\n",
      "Loss for epoch 80  and count  2 : 0.005681074084520029 with ratio of  tensor(0.8793)\n",
      "Average correct tiles testing: 4.56 | a mean tile choice of  11.507777  and a variance of 8.696223\n",
      "\n",
      "\n",
      "Loss for epoch 90  and count  2 : 0.005298082370039386 with ratio of  tensor(0.8907)\n",
      "Average correct tiles testing: 5.02 | a mean tile choice of  10.59  and a variance of 8.204391\n",
      "\n",
      "\n",
      "Loss for epoch 100  and count  2 : 0.004966673916981866 with ratio of  tensor(0.8970)\n",
      "Average correct tiles testing: 4.25 | a mean tile choice of  10.85  and a variance of 8.5791235\n",
      "\n",
      "\n",
      "Loss for epoch 110  and count  2 : 0.004713251640593322 with ratio of  tensor(0.9074)\n",
      "Average correct tiles testing: 4.45 | a mean tile choice of  10.554445  and a variance of 8.364084\n",
      "\n",
      "\n",
      "Loss for epoch 120  and count  2 : 0.00449300559121184 with ratio of  tensor(0.9200)\n",
      "Average correct tiles testing: 4.52 | a mean tile choice of  10.146666  and a variance of 7.9586616\n",
      "\n",
      "\n",
      "Count increase! Now at 3  with batch size 1\n",
      "Loss for epoch 130  and count  3 : 0.004320752382821714 with ratio of  tensor(0.9219)\n",
      "Average correct tiles testing: 4.02 | a mean tile choice of  11.147778  and a variance of 8.3293085\n",
      "\n",
      "\n",
      "Loss for epoch 140  and count  3 : 0.003958053172488387 with ratio of  tensor(0.8463)\n",
      "Average correct tiles testing: 4.72 | a mean tile choice of  10.63111  and a variance of 8.367343\n",
      "\n",
      "\n",
      "Loss for epoch 150  and count  3 : 0.0035880502860527485 with ratio of  tensor(0.8556)\n",
      "Average correct tiles testing: 4.49 | a mean tile choice of  11.671111  and a variance of 8.751674\n",
      "\n",
      "\n",
      "Loss for epoch 160  and count  3 : 0.003327688204590231 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 4.79 | a mean tile choice of  10.781111  and a variance of 8.581359\n",
      "\n",
      "\n",
      "Loss for epoch 170  and count  3 : 0.003135165876786535 with ratio of  tensor(0.8804)\n",
      "Average correct tiles testing: 4.02 | a mean tile choice of  11.677777  and a variance of 8.816762\n",
      "\n",
      "\n",
      "Loss for epoch 180  and count  3 : 0.002964430632807004 with ratio of  tensor(0.8900)\n",
      "Average correct tiles testing: 4.57 | a mean tile choice of  11.29  and a variance of 8.5594015\n",
      "\n",
      "\n",
      "Loss for epoch 190  and count  3 : 0.0028098750781888763 with ratio of  tensor(0.8941)\n",
      "Average correct tiles testing: 4.54 | a mean tile choice of  11.574445  and a variance of 8.691081\n",
      "\n",
      "\n",
      "Loss for epoch 200  and count  3 : 0.002679445106186904 with ratio of  tensor(0.9015)\n",
      "Average correct tiles testing: 4.46 | a mean tile choice of  10.952221  and a variance of 8.728412\n",
      "\n",
      "\n",
      "Loss for epoch 210  and count  3 : 0.0025781125489932797 with ratio of  tensor(0.9104)\n",
      "Average correct tiles testing: 4.61 | a mean tile choice of  11.39  and a variance of 8.86684\n",
      "\n",
      "\n",
      "Loss for epoch 220  and count  3 : 0.002492802027457704 with ratio of  tensor(0.9144)\n",
      "Average correct tiles testing: 4.52 | a mean tile choice of  11.886667  and a variance of 8.758914\n",
      "\n",
      "\n",
      "Loss for epoch 230  and count  3 : 0.0024255518791809058 with ratio of  tensor(0.9185)\n",
      "Average correct tiles testing: 4.39 | a mean tile choice of  11.07111  and a variance of 8.553429\n",
      "\n",
      "\n",
      "Loss for epoch 240  and count  3 : 0.0023558939372499785 with ratio of  tensor(0.9193)\n",
      "Average correct tiles testing: 4.56 | a mean tile choice of  12.081111  and a variance of 8.779076\n",
      "\n",
      "\n",
      "Count increase! Now at 4  with batch size 1\n",
      "Loss for epoch 250  and count  4 : 0.0022956375777721406 with ratio of  tensor(0.9222)\n",
      "Average correct tiles testing: 4.31 | a mean tile choice of  12.738889  and a variance of 8.722186\n",
      "\n",
      "\n",
      "Loss for epoch 260  and count  4 : 0.003706181485710355 with ratio of  tensor(0.7474)\n",
      "Average correct tiles testing: 4.18 | a mean tile choice of  12.450001  and a variance of 8.786371\n",
      "\n",
      "\n",
      "Loss for epoch 270  and count  4 : 0.003441518044952924 with ratio of  tensor(0.7822)\n",
      "Average correct tiles testing: 4.57 | a mean tile choice of  13.334445  and a variance of 8.929888\n",
      "\n",
      "\n",
      "Loss for epoch 280  and count  4 : 0.0032309534839199236 with ratio of  tensor(0.8000)\n",
      "Average correct tiles testing: 4.99 | a mean tile choice of  12.8944435  and a variance of 8.923045\n",
      "\n",
      "\n",
      "Loss for epoch 290  and count  4 : 0.0030585839009533325 with ratio of  tensor(0.8270)\n",
      "Average correct tiles testing: 4.89 | a mean tile choice of  12.386666  and a variance of 8.709707\n",
      "\n",
      "\n",
      "Loss for epoch 300  and count  4 : 0.0029212520056171344 with ratio of  tensor(0.8385)\n",
      "Average correct tiles testing: 4.69 | a mean tile choice of  13.575555  and a variance of 8.63226\n",
      "\n",
      "\n",
      "Loss for epoch 310  and count  4 : 0.002802985843930704 with ratio of  tensor(0.8452)\n",
      "Average correct tiles testing: 4.62 | a mean tile choice of  13.162222  and a variance of 8.833109\n",
      "\n",
      "\n",
      "Loss for epoch 320  and count  4 : 0.0026920908765168863 with ratio of  tensor(0.8530)\n",
      "Average correct tiles testing: 4.78 | a mean tile choice of  12.355556  and a variance of 8.856336\n",
      "\n",
      "\n",
      "Loss for epoch 330  and count  4 : 0.0026058448168138665 with ratio of  tensor(0.8630)\n",
      "Average correct tiles testing: 4.68 | a mean tile choice of  12.692224  and a variance of 8.713063\n",
      "\n",
      "\n",
      "Loss for epoch 340  and count  4 : 0.002528461677332719 with ratio of  tensor(0.8700)\n",
      "Average correct tiles testing: 5.26 | a mean tile choice of  12.622223  and a variance of 8.798117\n",
      "\n",
      "\n",
      "Loss for epoch 350  and count  4 : 0.0024582146575752024 with ratio of  tensor(0.8763)\n",
      "Average correct tiles testing: 4.94 | a mean tile choice of  13.357778  and a variance of 8.933899\n",
      "\n",
      "\n",
      "Loss for epoch 360  and count  4 : 0.002402771102109303 with ratio of  tensor(0.8830)\n",
      "Average correct tiles testing: 4.9 | a mean tile choice of  12.597778  and a variance of 8.828972\n",
      "\n",
      "\n",
      "Loss for epoch 370  and count  4 : 0.002346142091943572 with ratio of  tensor(0.8874)\n",
      "Average correct tiles testing: 5.05 | a mean tile choice of  13.339999  and a variance of 8.816313\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 380  and count  4 : 0.0023005379057334115 with ratio of  tensor(0.8867)\n",
      "Average correct tiles testing: 5.55 | a mean tile choice of  13.016666  and a variance of 8.857242\n",
      "\n",
      "\n",
      "Count increase! Now at 5  with batch size 1\n",
      "Loss for epoch 390  and count  5 : 0.0022571453131968156 with ratio of  tensor(0.8915)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  12.324444  and a variance of 8.756221\n",
      "\n",
      "\n",
      "Loss for epoch 400  and count  5 : 0.004278908890555612 with ratio of  tensor(0.6807)\n",
      "Average correct tiles testing: 5.16 | a mean tile choice of  12.607778  and a variance of 8.84965\n",
      "\n",
      "\n",
      "Loss for epoch 410  and count  5 : 0.004025408150046133 with ratio of  tensor(0.6993)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  14.011111  and a variance of 9.085614\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 420  and count  5 : 0.0037913455253389353 with ratio of  tensor(0.7244)\n",
      "Average correct tiles testing: 5.83 | a mean tile choice of  13.036667  and a variance of 9.095617\n",
      "\n",
      "\n",
      "Loss for epoch 430  and count  5 : 0.0036355068367750695 with ratio of  tensor(0.7333)\n",
      "Average correct tiles testing: 5.6 | a mean tile choice of  13.258888  and a variance of 9.070893\n",
      "\n",
      "\n",
      "Loss for epoch 440  and count  5 : 0.003501754092091384 with ratio of  tensor(0.7319)\n",
      "Average correct tiles testing: 5.42 | a mean tile choice of  13.743334  and a variance of 8.94726\n",
      "\n",
      "\n",
      "Loss for epoch 450  and count  5 : 0.0033872923631376277 with ratio of  tensor(0.7470)\n",
      "Average correct tiles testing: 5.59 | a mean tile choice of  12.825557  and a variance of 8.854155\n",
      "\n",
      "\n",
      "Loss for epoch 460  and count  5 : 0.00326752191176638 with ratio of  tensor(0.7556)\n",
      "Average correct tiles testing: 5.33 | a mean tile choice of  13.084443  and a variance of 9.127827\n",
      "\n",
      "\n",
      "Loss for epoch 470  and count  5 : 0.0031669114978285506 with ratio of  tensor(0.7619)\n",
      "Average correct tiles testing: 5.37 | a mean tile choice of  13.3511095  and a variance of 9.069038\n",
      "\n",
      "\n",
      "Loss for epoch 480  and count  5 : 0.0030660595810816935 with ratio of  tensor(0.7615)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.460001  and a variance of 9.093523\n",
      "\n",
      "\n",
      "Loss for epoch 490  and count  5 : 0.0029737425480076732 with ratio of  tensor(0.7704)\n",
      "Average correct tiles testing: 5.07 | a mean tile choice of  13.384443  and a variance of 9.216288\n",
      "\n",
      "\n",
      "Loss for epoch 500  and count  5 : 0.002880609155787776 with ratio of  tensor(0.7767)\n",
      "Average correct tiles testing: 5.71 | a mean tile choice of  13.325557  and a variance of 9.169049\n",
      "\n",
      "\n",
      "Loss for epoch 510  and count  5 : 0.0027923674482735806 with ratio of  tensor(0.7796)\n",
      "Average correct tiles testing: 5.12 | a mean tile choice of  13.093334  and a variance of 9.108307\n",
      "\n",
      "\n",
      "Loss for epoch 520  and count  5 : 0.002696640848783621 with ratio of  tensor(0.7841)\n",
      "Average correct tiles testing: 5.65 | a mean tile choice of  13.662223  and a variance of 9.268754\n",
      "\n",
      "\n",
      "Loss for epoch 530  and count  5 : 0.002632773009633335 with ratio of  tensor(0.7948)\n",
      "Average correct tiles testing: 5.2 | a mean tile choice of  13.361111  and a variance of 9.076862\n",
      "\n",
      "\n",
      "Loss for epoch 540  and count  5 : 0.0025556077405538722 with ratio of  tensor(0.8011)\n",
      "Average correct tiles testing: 5.58 | a mean tile choice of  13.86  and a variance of 9.088392\n",
      "\n",
      "\n",
      "Loss for epoch 550  and count  5 : 0.0024821453826734795 with ratio of  tensor(0.8067)\n",
      "Average correct tiles testing: 5.61 | a mean tile choice of  12.901111  and a variance of 8.999692\n",
      "\n",
      "\n",
      "Loss for epoch 560  and count  5 : 0.0024196223036657707 with ratio of  tensor(0.8089)\n",
      "Average correct tiles testing: 5.5 | a mean tile choice of  13.116667  and a variance of 9.356414\n",
      "\n",
      "\n",
      "Loss for epoch 570  and count  5 : 0.002364716379379388 with ratio of  tensor(0.8159)\n",
      "Average correct tiles testing: 5.69 | a mean tile choice of  13.366667  and a variance of 9.1735735\n",
      "\n",
      "\n",
      "Loss for epoch 580  and count  5 : 0.00229897301789606 with ratio of  tensor(0.8181)\n",
      "Average correct tiles testing: 5.71 | a mean tile choice of  12.552222  and a variance of 9.095039\n",
      "\n",
      "\n",
      "Loss for epoch 590  and count  5 : 0.0022509381227428095 with ratio of  tensor(0.8222)\n",
      "Average correct tiles testing: 5.7 | a mean tile choice of  13.178888  and a variance of 9.284167\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 600  and count  5 : 0.0022000690537970513 with ratio of  tensor(0.8304)\n",
      "Average correct tiles testing: 5.84 | a mean tile choice of  13.684444  and a variance of 9.155752\n",
      "\n",
      "\n",
      "Loss for epoch 610  and count  5 : 0.0021617703545295324 with ratio of  tensor(0.8307)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.845557  and a variance of 9.127849\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 620  and count  5 : 0.0021265570426476188 with ratio of  tensor(0.8330)\n",
      "Average correct tiles testing: 5.93 | a mean tile choice of  12.857778  and a variance of 9.157719\n",
      "\n",
      "\n",
      "Loss for epoch 630  and count  5 : 0.0020963573188055307 with ratio of  tensor(0.8378)\n",
      "Average correct tiles testing: 5.75 | a mean tile choice of  13.345556  and a variance of 9.184172\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 640  and count  5 : 0.0020616967457074984 with ratio of  tensor(0.8359)\n",
      "Average correct tiles testing: 5.99 | a mean tile choice of  13.08  and a variance of 9.151118\n",
      "\n",
      "\n",
      "Loss for epoch 650  and count  5 : 0.002034676792876174 with ratio of  tensor(0.8359)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  13.093334  and a variance of 9.205398\n",
      "\n",
      "\n",
      "Loss for epoch 660  and count  5 : 0.002015228175247709 with ratio of  tensor(0.8411)\n",
      "Average correct tiles testing: 5.15 | a mean tile choice of  13.091111  and a variance of 9.01807\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 670  and count  5 : 0.0019965036275486152 with ratio of  tensor(0.8422)\n",
      "Average correct tiles testing: 6.03 | a mean tile choice of  13.426667  and a variance of 9.071204\n",
      "\n",
      "\n",
      "Loss for epoch 680  and count  5 : 0.001981088851656144 with ratio of  tensor(0.8444)\n",
      "Average correct tiles testing: 5.29 | a mean tile choice of  13.451111  and a variance of 8.917282\n",
      "\n",
      "\n",
      "Optim lr step\n",
      "Loss for epoch 690  and count  5 : 0.0019654411206526372 with ratio of  tensor(0.8478)\n",
      "Average correct tiles testing: 6.14 | a mean tile choice of  12.704445  and a variance of 9.022873\n",
      "\n",
      "\n",
      "Loss for epoch 700  and count  5 : 0.0019540934603234444 with ratio of  tensor(0.8552)\n",
      "Average correct tiles testing: 5.28 | a mean tile choice of  14.470001  and a variance of 9.230028\n",
      "\n",
      "\n",
      "Loss for epoch 710  and count  5 : 0.0019437967333942653 with ratio of  tensor(0.8556)\n",
      "Average correct tiles testing: 6.02 | a mean tile choice of  13.286668  and a variance of 9.188482\n",
      "\n",
      "\n",
      "Loss for epoch 720  and count  5 : 0.0019336293201195076 with ratio of  tensor(0.8537)\n",
      "Average correct tiles testing: 5.65 | a mean tile choice of  13.798889  and a variance of 9.060407\n",
      "\n",
      "\n",
      "Loss for epoch 730  and count  5 : 0.0019202249427326024 with ratio of  tensor(0.8519)\n",
      "Average correct tiles testing: 5.52 | a mean tile choice of  14.706665  and a variance of 9.067694\n",
      "\n",
      "\n",
      "Loss for epoch 740  and count  5 : 0.0019116569555869016 with ratio of  tensor(0.8522)\n",
      "Average correct tiles testing: 5.63 | a mean tile choice of  13.587778  and a variance of 9.265906\n",
      "\n",
      "\n",
      "Loss for epoch 750  and count  5 : 0.0019030541597749107 with ratio of  tensor(0.8522)\n",
      "Average correct tiles testing: 5.43 | a mean tile choice of  13.796668  and a variance of 9.432832\n",
      "\n",
      "\n",
      "Loss for epoch 760  and count  5 : 0.0018950642229174264 with ratio of  tensor(0.8530)\n",
      "Average correct tiles testing: 5.61 | a mean tile choice of  13.605556  and a variance of 8.975333\n",
      "\n",
      "\n",
      "Loss for epoch 770  and count  5 : 0.001886678785958793 with ratio of  tensor(0.8548)\n",
      "Average correct tiles testing: 5.46 | a mean tile choice of  12.777779  and a variance of 9.215845\n",
      "\n",
      "\n",
      "Loss for epoch 780  and count  5 : 0.0018748913119391848 with ratio of  tensor(0.8567)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  12.816668  and a variance of 9.442913\n",
      "\n",
      "\n",
      "Loss for epoch 790  and count  5 : 0.001866823542319859 with ratio of  tensor(0.8548)\n",
      "Average correct tiles testing: 5.8 | a mean tile choice of  13.51111  and a variance of 9.238264\n",
      "\n",
      "\n",
      "Loss for epoch 800  and count  5 : 0.0018591055800789035 with ratio of  tensor(0.8563)\n",
      "Average correct tiles testing: 5.62 | a mean tile choice of  14.7288885  and a variance of 8.940084\n",
      "\n",
      "\n",
      "Loss for epoch 810  and count  5 : 0.001848945134455183 with ratio of  tensor(0.8593)\n",
      "Average correct tiles testing: 5.34 | a mean tile choice of  13.911111  and a variance of 9.097665\n",
      "\n",
      "\n",
      "Loss for epoch 820  and count  5 : 0.0018388788234248448 with ratio of  tensor(0.8574)\n",
      "Average correct tiles testing: 5.62 | a mean tile choice of  13.403334  and a variance of 9.114114\n",
      "\n",
      "\n",
      "Loss for epoch 830  and count  5 : 0.001830638662892549 with ratio of  tensor(0.8619)\n",
      "Average correct tiles testing: 5.34 | a mean tile choice of  13.414445  and a variance of 9.111377\n",
      "\n",
      "\n",
      "Loss for epoch 840  and count  5 : 0.0018227739377956217 with ratio of  tensor(0.8648)\n",
      "Average correct tiles testing: 5.76 | a mean tile choice of  12.854445  and a variance of 9.153306\n",
      "\n",
      "\n",
      "Loss for epoch 850  and count  5 : 0.001813824371395943 with ratio of  tensor(0.8652)\n",
      "Average correct tiles testing: 5.49 | a mean tile choice of  13.62  and a variance of 9.286556\n",
      "\n",
      "\n",
      "Loss for epoch 860  and count  5 : 0.0018063039078454798 with ratio of  tensor(0.8652)\n",
      "Average correct tiles testing: 5.42 | a mean tile choice of  13.334445  and a variance of 9.275265\n",
      "\n",
      "\n",
      "Loss for epoch 870  and count  5 : 0.001798790319201847 with ratio of  tensor(0.8644)\n",
      "Average correct tiles testing: 5.58 | a mean tile choice of  13.544445  and a variance of 8.889187\n",
      "\n",
      "\n",
      "Loss for epoch 880  and count  5 : 0.0017913998746856427 with ratio of  tensor(0.8685)\n",
      "Average correct tiles testing: 5.72 | a mean tile choice of  13.585555  and a variance of 9.270829\n",
      "\n",
      "\n",
      "Loss for epoch 890  and count  5 : 0.0017831356178309458 with ratio of  tensor(0.8730)\n",
      "Average correct tiles testing: 5.48 | a mean tile choice of  13.527778  and a variance of 9.235075\n",
      "\n",
      "\n",
      "Loss for epoch 900  and count  5 : 0.0017756638664286584 with ratio of  tensor(0.8704)\n",
      "Average correct tiles testing: 5.55 | a mean tile choice of  13.042223  and a variance of 9.158231\n",
      "\n",
      "\n",
      "Loss for epoch 910  and count  5 : 0.0017682516883360223 with ratio of  tensor(0.8696)\n",
      "Average correct tiles testing: 6.08 | a mean tile choice of  13.176667  and a variance of 9.201549\n",
      "\n",
      "\n",
      "Loss for epoch 920  and count  5 : 0.0017620560360956006 with ratio of  tensor(0.8707)\n",
      "Average correct tiles testing: 5.87 | a mean tile choice of  13.017779  and a variance of 9.14386\n",
      "\n",
      "\n",
      "Loss for epoch 930  and count  5 : 0.0017559715630098556 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 5.79 | a mean tile choice of  13.455555  and a variance of 9.21405\n",
      "\n",
      "\n",
      "Loss for epoch 940  and count  5 : 0.0017499590624356642 with ratio of  tensor(0.8726)\n",
      "Average correct tiles testing: 5.97 | a mean tile choice of  13.661111  and a variance of 9.219522\n",
      "\n",
      "\n",
      "Loss for epoch 950  and count  5 : 0.0017443689587526023 with ratio of  tensor(0.8696)\n",
      "Average correct tiles testing: 5.47 | a mean tile choice of  13.373333  and a variance of 8.896755\n",
      "\n",
      "\n",
      "Loss for epoch 960  and count  5 : 0.0017389342262564848 with ratio of  tensor(0.8741)\n",
      "Average correct tiles testing: 5.54 | a mean tile choice of  13.543332  and a variance of 9.260556\n",
      "\n",
      "\n",
      "Loss for epoch 970  and count  5 : 0.0017348468327933611 with ratio of  tensor(0.8711)\n",
      "Average correct tiles testing: 5.66 | a mean tile choice of  12.946667  and a variance of 9.330492\n",
      "\n",
      "\n",
      "Loss for epoch 980  and count  5 : 0.0017296831115769843 with ratio of  tensor(0.8737)\n",
      "Average correct tiles testing: 5.88 | a mean tile choice of  13.935555  and a variance of 9.100479\n",
      "\n",
      "\n",
      "Loss for epoch 990  and count  5 : 0.001724725477785493 with ratio of  tensor(0.8730)\n",
      "Average correct tiles testing: 5.53 | a mean tile choice of  13.731111  and a variance of 9.121807\n",
      "\n",
      "\n",
      "Loss for epoch 1000  and count  5 : 0.0017223719397831399 with ratio of  tensor(0.8715)\n",
      "Average correct tiles testing: 5.44 | a mean tile choice of  13.541111  and a variance of 9.090029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "\n",
    "epochs = 1000\n",
    "width = width = 3 #map_w\n",
    "height = height = 3 #map_h\n",
    "num_tiles = num_tiles\n",
    "diffusion_steps_GRU = 13\n",
    "steps = 8\n",
    "step_size = 5\n",
    "kernel_size = 3\n",
    "l_sum_np = 0\n",
    "batch_size = 1\n",
    "loss = 0\n",
    "count = 1\n",
    "threshold = 0.92\n",
    "test_len = 100\n",
    "prev_max = 4.5 # Initial threshold before we start dropping the LR. We don't want to drop it aggresively until at least half the test tiles placed are valid\n",
    "\n",
    "curriculum = True\n",
    "switch = True\n",
    "\n",
    "index_list = np.arange(train_size)\n",
    "id_list = np.arange(width)\n",
    "index = np.arange(width*height)\n",
    "\n",
    "index_even = np.arange(5)*2\n",
    "index_odd = np.arange(4)*2+1\n",
    "\n",
    "#gru = GRU_WFC(num_tiles, 0, height, width, diffusion_steps_GRU, kernel_size, bias_sca+le = 0.25, deep = False)\n",
    "gru = GRU_WFC_2(num_tiles)\n",
    "device = 'cuda:0'\n",
    "#gru.to(device)\n",
    "\n",
    "loss_func =  nn.MSELoss() # nn.L1Loss() #\n",
    "l_kl = torch.nn.KLDivLoss(reduction=\"batchmean\", log_target = True)\n",
    "lbce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#loss_l1 = nn.L1Loss()\n",
    "optimizer = torch.optim.NAdam(gru.parameters(), lr = 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.79)\n",
    "\n",
    "map_ = torch.zeros(train_size, num_tiles, height, width)\n",
    "for ii in range(train_size):\n",
    "    map_[ii] = maps_training[ii, int(diffusion_steps[ii]), :, :, :]\n",
    "\n",
    "\n",
    "_, id_set = torch.max(map_, dim = 1)\n",
    "\n",
    "va, m = (torch.var_mean(id_set.float(), 0))\n",
    "print('The training dataset has a mean tile choice of ', m.mean(),'with a mean std of', va.mean().sqrt())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    v_ratio = 0\n",
    "    np.random.shuffle(index_list)\n",
    "\n",
    "    for i1 in range(train_size):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            id = index_list[i1]\n",
    "            dfinal = diffusion_steps[id]\n",
    "            h_init = maps_training[id, 0:int(dfinal)+1]\n",
    "\n",
    "        if curriculum:\n",
    "            # Replaces a random tile with a noise vector. Curriculum adds another instance of noise when [% valid choices > 0.9]\n",
    "            np.random.shuffle(index)\n",
    "            h_init = h_init.requires_grad_(False)\n",
    "            fmap = h_init[int(dfinal)].squeeze().clone()\n",
    "\n",
    "            for k in range(len(index_even)):\n",
    "                id_lin = index_even[k]\n",
    "                with torch.no_grad():\n",
    "                    id_x = id_lin % width\n",
    "                    id_y = id_lin // height\n",
    "                    mask = h_init[0,:,id_x,id_y].cpu().clone()\n",
    "                    fmap[:,id_x,id_y] = fmap[:,id_x,id_y]*0 + mask\n",
    "\n",
    "            for k in range(count-1):\n",
    "                id_lin = index_odd[k]\n",
    "                with torch.no_grad():\n",
    "                    id_x = id_lin % width\n",
    "                    id_y = id_lin // height\n",
    "                    mask = h_init[0,:,id_x,id_y].cpu().clone()\n",
    "                    fmap[:,id_x,id_y] = fmap[:,id_x,id_y]*0 + mask\n",
    "            \n",
    "                    \n",
    "            h_init = h_init.requires_grad_(True)\n",
    "            fmap = fmap.unsqueeze(0)\n",
    "\n",
    "        map_wfc_retained = gru.forward(fmap, key, 10, False, 0).squeeze() #int(dfinal[m]), training = False).squeeze()\n",
    "        lv = loss_func(map_wfc_retained, h_init[int(dfinal)]) / count\n",
    "        loss += lv\n",
    "\n",
    "        # Summing valid tiles\n",
    "        with torch.no_grad():\n",
    "            _, id_pred = torch.max(map_wfc_retained.clone().cpu().detach(), dim = 0)\n",
    "            _, v = validator(id_pred, key)\n",
    "            v_ratio += torch.clamp(v, 0, 1).sum()/(height*width)\n",
    "\n",
    "        l_sum_np += lv.clone().cpu().detach().numpy()\n",
    "        if (batch_size == 1) or (i1%batch_size == 0 and i1 > 0):\n",
    "            loss = loss/batch_size\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "            loss = 0\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        vsum = torch.zeros(test_len, height, width)\n",
    "        idsum = torch.zeros(test_len, height, width)\n",
    "        for k in range(test_len):\n",
    "            h_noise = torch.rand_like(h_init[0].clone().squeeze().unsqueeze(0))\n",
    "            map_wfc_noise = gru.forward(h_noise, key, 10, False, 0).squeeze()\n",
    "            _, id_noise = torch.max(map_wfc_noise, dim = 0)\n",
    "\n",
    "            _, v = validator(id_noise, key)\n",
    "            idsum[k] = id_noise\n",
    "            vsum[k] = v\n",
    "\n",
    "            \n",
    "        va, me = torch.var_mean(idsum, dim = 0)\n",
    "        print()\n",
    "        if v_ratio / train_size > threshold and epoch > 20:\n",
    "            count += 1\n",
    "            scheduler.step()\n",
    "            #batch_size += 1\n",
    "            if count >= 4:\n",
    "                threshold = 0.89\n",
    "\n",
    "            if count > 5: #width*height:\n",
    "                count = 5 # width*height\n",
    "                test_len = 1000\n",
    "                if switch:\n",
    "                    print('We made it to 9 randoms!')\n",
    "                    switch = False\n",
    "\n",
    "            print('Count increase! Now at', count, ' with batch size', batch_size)\n",
    "        if vsum.sum().numpy()/test_len > prev_max:\n",
    "                prev_max = vsum.sum().numpy()/test_len\n",
    "                print('Optim lr step')\n",
    "                scheduler.step()\n",
    "                \n",
    "        print('Loss for epoch', epoch+1,' and count ', count, ':', l_sum_np / (train_size), 'with ratio of ', v_ratio / train_size)\n",
    "        print('Average correct tiles testing:', vsum.sum().numpy()/test_len, '| a mean tile choice of ', me.mean().numpy(), ' and a variance of', va.mean().sqrt().numpy())     \n",
    "        print()\n",
    "    l_sum_np = 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  tensor(20.5287)  and variance  tensor(7.1775)\n",
      "Total valid points tensor(267767)  out of 360000  =  tensor(0.7438)  percent correctness\n"
     ]
    }
   ],
   "source": [
    "# testing block\n",
    "\n",
    "v_sum = 0\n",
    "width = 60\n",
    "height = width\n",
    "g = 0\n",
    "#\n",
    "gg = 100\n",
    "id_nl = torch.zeros((gg, height, width))\n",
    "with torch.no_grad():\n",
    "    for it in range(1):\n",
    "        for k in range(gg):\n",
    "            \n",
    "            h_noise = torch.rand((1, num_tiles, height, width))\n",
    "            map_wfc_noise = gru.forward(h_noise, key, 30, False, 0).squeeze()\n",
    "            \n",
    "            _, id_noise = torch.max(map_wfc_noise, dim = 0)\n",
    "\n",
    "            id_nl[k] = id_noise.squeeze()\n",
    "\n",
    "            valid, v = validator(id_noise, key)\n",
    "            v = torch.clamp(v, 0, 1).sum()\n",
    "            v_sum += v\n",
    "\n",
    "    \n",
    "var, me= torch.var_mean(id_nl, dim=0)\n",
    "print('mean of',me.mean().numpy(), ' and a mean std ', var.mean().sqrt().numpy())\n",
    "print('Total valid points', v_sum, ' out of', gg*width*height,' = ', v_sum/(gg*(width*height)),' percent correctness')\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
